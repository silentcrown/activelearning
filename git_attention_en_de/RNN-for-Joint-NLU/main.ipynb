{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# @author: cer\n",
    "import tensorflow as tf\n",
    "from data import *\n",
    "# from model import Model\n",
    "from model import Model\n",
    "from my_metrics import *\n",
    "from tensorflow.python import debug as tf_debug\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_steps = 50\n",
    "embedding_size = 64\n",
    "hidden_size = 100\n",
    "n_layers = 2\n",
    "batch_size = 16\n",
    "vocab_size = 871\n",
    "slot_size = 122\n",
    "intent_size = 22\n",
    "epoch_num = 50\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = Model(input_steps, embedding_size, hidden_size, vocab_size, slot_size,\n",
    "                 intent_size, epoch_num, batch_size, n_layers)\n",
    "    model.build()\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(is_debug=False):\n",
    "    model = get_model()\n",
    "    sess = tf.Session()\n",
    "    if is_debug:\n",
    "        sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "        sess.add_tensor_filter(\"has_inf_or_nan\", tf_debug.has_inf_or_nan)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # print(tf.trainable_variables())\n",
    "    train_data = open(\"dataset/atis-2.train.w-intent.iob\", \"r\").readlines()\n",
    "    test_data = open(\"dataset/atis-2.dev.w-intent.iob\", \"r\").readlines()\n",
    "    train_data_ed = data_pipeline(train_data)\n",
    "    test_data_ed = data_pipeline(test_data)\n",
    "    word2index, index2word, slot2index, index2slot, intent2index, index2intent = \\\n",
    "        get_info_from_training_data(train_data_ed)\n",
    "    # print(\"slot2index: \", slot2index)\n",
    "    # print(\"index2slot: \", index2slot)\n",
    "    index_train = to_index(train_data_ed, word2index, slot2index, intent2index)\n",
    "    index_test = to_index(test_data_ed, word2index, slot2index, intent2index)\n",
    "    for epoch in range(epoch_num):\n",
    "        mean_loss = 0.0\n",
    "        train_loss = 0.0\n",
    "        for i, batch in enumerate(getBatch(batch_size, index_train)):\n",
    "            # 执行一个batch的训练\n",
    "            _, loss, decoder_prediction, intent, mask, slot_W = model.step(sess, \"train\", batch)\n",
    "            # if i == 0:\n",
    "            #     index = 0\n",
    "            #     print(\"training debug:\")\n",
    "            #     print(\"input:\", list(zip(*batch))[0][index])\n",
    "            #     print(\"length:\", list(zip(*batch))[1][index])\n",
    "            #     print(\"mask:\", mask[index])\n",
    "            #     print(\"target:\", list(zip(*batch))[2][index])\n",
    "            #     # print(\"decoder_targets_one_hot:\")\n",
    "            #     # for one in decoder_targets_one_hot[index]:\n",
    "            #     #     print(\" \".join(map(str, one)))\n",
    "            #     print(\"decoder_logits: \")\n",
    "            #     for one in decoder_logits[index]:\n",
    "            #         print(\" \".join(map(str, one)))\n",
    "            #     print(\"slot_W:\", slot_W)\n",
    "            #     print(\"decoder_prediction:\", decoder_prediction[index])\n",
    "            #     print(\"intent:\", list(zip(*batch))[3][index])\n",
    "            # mean_loss += loss\n",
    "            # train_loss += loss\n",
    "            # if i % 10 == 0:\n",
    "            #     if i > 0:\n",
    "            #         mean_loss = mean_loss / 10.0\n",
    "            #     print('Average train loss at epoch %d, step %d: %f' % (epoch, i, mean_loss))\n",
    "            #     mean_loss = 0\n",
    "        train_loss /= (i + 1)\n",
    "        print(\"[Epoch {}] Average train loss: {}\".format(epoch, train_loss))\n",
    "\n",
    "        # 每训一个epoch，测试一次\n",
    "        pred_slots = []\n",
    "        slot_accs = []\n",
    "        intent_accs = []\n",
    "        for j, batch in enumerate(getBatch(batch_size, index_test)):\n",
    "            decoder_prediction, intent = model.step(sess, \"test\", batch)\n",
    "            decoder_prediction = np.transpose(decoder_prediction, [1, 0])\n",
    "            if j == 0:\n",
    "                index = random.choice(range(len(batch)))\n",
    "                # index = 0\n",
    "                sen_len = batch[index][1]\n",
    "                print(\"Input Sentence        : \", index_seq2word(batch[index][0], index2word)[:sen_len])\n",
    "                print(\"Slot Truth            : \", index_seq2slot(batch[index][2], index2slot)[:sen_len])\n",
    "                print(\"Slot Prediction       : \", index_seq2slot(decoder_prediction[index], index2slot)[:sen_len])\n",
    "                print(\"Intent Truth          : \", index2intent[batch[index][3]])\n",
    "                print(\"Intent Prediction     : \", index2intent[intent[index]])\n",
    "            slot_pred_length = list(np.shape(decoder_prediction))[1]\n",
    "            pred_padded = np.lib.pad(decoder_prediction, ((0, 0), (0, input_steps-slot_pred_length)),\n",
    "                                     mode=\"constant\", constant_values=0)\n",
    "            pred_slots.append(pred_padded)\n",
    "            # print(\"slot_pred_length: \", slot_pred_length)\n",
    "            true_slot = np.array((list(zip(*batch))[2]))\n",
    "            true_length = np.array((list(zip(*batch))[1]))\n",
    "            true_slot = true_slot[:, :slot_pred_length]\n",
    "            # print(np.shape(true_slot), np.shape(decoder_prediction))\n",
    "            # print(true_slot, decoder_prediction)\n",
    "            slot_acc = accuracy_score(true_slot, decoder_prediction, true_length)\n",
    "            intent_acc = accuracy_score(list(zip(*batch))[3], intent)\n",
    "            # print(\"slot accuracy: {}, intent accuracy: {}\".format(slot_acc, intent_acc))\n",
    "            slot_accs.append(slot_acc)\n",
    "            intent_accs.append(intent_acc)\n",
    "        pred_slots_a = np.vstack(pred_slots)\n",
    "        # print(\"pred_slots_a: \", pred_slots_a.shape)\n",
    "        true_slots_a = np.array(list(zip(*index_test))[2])[:pred_slots_a.shape[0]]\n",
    "        # print(\"true_slots_a: \", true_slots_a.shape)\n",
    "        print(\"Intent accuracy for epoch {}: {}\".format(epoch, np.average(intent_accs)))\n",
    "        print(\"Slot accuracy for epoch {}: {}\".format(epoch, np.average(slot_accs)))\n",
    "        print(\"Slot F1 score for epoch {}: {}\".format(epoch, f1_for_sequence_batch(true_slots_a, pred_slots_a)))\n",
    "\n",
    "\n",
    "def test_data():\n",
    "    train_data = open(\"dataset/atis-2.train.w-intent.iob\", \"r\").readlines()\n",
    "    test_data = open(\"dataset/atis-2.dev.w-intent.iob\", \"r\").readlines()\n",
    "    train_data_ed = data_pipeline(train_data)\n",
    "    test_data_ed = data_pipeline(test_data)\n",
    "    word2index, index2word, slot2index, index2slot, intent2index, index2intent = \\\n",
    "        get_info_from_training_data(train_data_ed)\n",
    "    # print(\"slot2index: \", slot2index)\n",
    "    # print(\"index2slot: \", index2slot)\n",
    "    index_train = to_index(train_data_ed, word2index, slot2index, intent2index)\n",
    "    index_test = to_index(test_data_ed, word2index, slot2index, intent2index)\n",
    "    batch = next(getBatch(batch_size, index_test))\n",
    "    unziped = list(zip(*batch))\n",
    "    print(\"word num: \", len(word2index.keys()), \"slot num: \", len(slot2index.keys()), \"intent num: \",\n",
    "          len(intent2index.keys()))\n",
    "    print(np.shape(unziped[0]), np.shape(unziped[1]), np.shape(unziped[2]), np.shape(unziped[3]))\n",
    "    print(np.transpose(unziped[0], [1, 0]))\n",
    "    print(unziped[1])\n",
    "    print(np.shape(list(zip(*index_test))[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('encoder_outputs: ', <tf.Tensor 'concat:0' shape=(50, 16, 200) dtype=float32>)\n",
      "('encoder_outputs[0]: ', <tf.Tensor 'strided_slice:0' shape=(16, 200) dtype=float32>)\n",
      "('encoder_final_state_c: ', <tf.Tensor 'concat_1:0' shape=(?, 200) dtype=float32>)\n",
      "('outputs', <tf.Tensor 'decode/decoder/while/BasicDecoderStep/decoder/output_projection_wrapper/output_projection_wrapper_1/BiasAdd:0' shape=(16, 122) dtype=float32>)\n",
      "('outputs: ', BasicDecoderOutput(rnn_output=<tf.Tensor 'decode/decoder/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, 16, 122) dtype=float32>, sample_id=<tf.Tensor 'decode/decoder/TensorArrayStack_1/TensorArrayGatherV3:0' shape=(?, 16) dtype=int32>))\n",
      "('outputs.rnn_output: ', <tf.Tensor 'decode/decoder/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, 16, 122) dtype=float32>)\n",
      "('outputs.sample_id: ', <tf.Tensor 'decode/decoder/TensorArrayStack_1/TensorArrayGatherV3:0' shape=(?, 16) dtype=int32>)\n",
      "('decoder_targets_true_length: ', <tf.Tensor 'strided_slice_1:0' shape=(?, 16) dtype=int32>)\n",
      "('vars for loss function: ', (<tf.Variable 'embedding:0' shape=(871, 64) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/fw/lstm_cell/kernel:0' shape=(164, 400) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/fw/lstm_cell/bias:0' shape=(400,) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/bw/lstm_cell/kernel:0' shape=(164, 400) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/bw/lstm_cell/bias:0' shape=(400,) dtype=float32_ref>, <tf.Variable 'slot_W:0' shape=(200, 122) dtype=float32_ref>, <tf.Variable 'slot_b:0' shape=(122,) dtype=float32_ref>, <tf.Variable 'intent_W:0' shape=(200, 22) dtype=float32_ref>, <tf.Variable 'intent_b:0' shape=(22,) dtype=float32_ref>, <tf.Variable 'decode/memory_layer/kernel:0' shape=(200, 100) dtype=float32_ref>, <tf.Variable 'decode/decoder/output_projection_wrapper/attention_wrapper/lstm_cell/kernel:0' shape=(564, 800) dtype=float32_ref>, <tf.Variable 'decode/decoder/output_projection_wrapper/attention_wrapper/lstm_cell/bias:0' shape=(800,) dtype=float32_ref>, <tf.Variable 'decode/decoder/output_projection_wrapper/attention_wrapper/bahdanau_attention/query_layer/kernel:0' shape=(200, 100) dtype=float32_ref>, <tf.Variable 'decode/decoder/output_projection_wrapper/attention_wrapper/bahdanau_attention/attention_v:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'decode/decoder/output_projection_wrapper/attention_wrapper/attention_layer/kernel:0' shape=(400, 100) dtype=float32_ref>, <tf.Variable 'decode/decoder/output_projection_wrapper/kernel:0' shape=(100, 122) dtype=float32_ref>, <tf.Variable 'decode/decoder/output_projection_wrapper/bias:0' shape=(122,) dtype=float32_ref>))\n",
      "[Epoch 0] Average train loss: 0.0\n",
      "('Input Sentence        : ', [\"i'd\", 'like', 'to', 'see', 'all', 'the', 'flights', 'from', 'boston', 'to', 'philadelphia'])\n",
      "('Slot Truth            : ', ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name'])\n",
      "('Slot Prediction       : ', ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name'])\n",
      "('Intent Truth          : ', 'atis_flight')\n",
      "('Intent Prediction     : ', 'atis_flight')\n",
      "Intent accuracy for epoch 0: 0.852822580645\n",
      "Slot accuracy for epoch 0: 0.742961749731\n",
      "Slot F1 score for epoch 0: 0.741348870056\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b9fab696a7a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# train(is_debug=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# test_data()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-2abff22ba3df>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(is_debug)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# 执行一个batch的训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslot_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;31m# if i == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m#     index = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/works/yexin/yexin/git_attention_en_de/RNN-for-Joint-NLU/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, sess, mode, trarin_batch)\u001b[0m\n\u001b[1;32m    193\u001b[0m                          self.encoder_inputs_actual_length: unziped[1]}\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_feeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/works/dl-tools/anaconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/works/dl-tools/anaconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/works/dl-tools/anaconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/works/dl-tools/anaconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/works/dl-tools/anaconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # train(is_debug=True)\n",
    "    # test_data()\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfenv.v1.2]",
   "language": "python",
   "name": "conda-env-tfenv.v1.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
