{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/sparse/lil.py:19: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _csparsetools\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:165: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._shortest_path import shortest_path, floyd_warshall, dijkstra,\\\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/sparse/csgraph/_validation.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._tools import csgraph_to_dense, csgraph_from_dense,\\\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:167: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._traversal import breadth_first_order, depth_first_order, \\\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:169: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._min_spanning_tree import minimum_spanning_tree\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:170: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._reordering import reverse_cuthill_mckee, maximum_bipartite_matching, \\\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/special/__init__.py:640: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ufuncs import *\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/linalg/basic.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._solve_toeplitz import levinson\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/linalg/__init__.py:207: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._decomp_update import *\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/special/_ellip_harm.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ellip_harm_2 import _ellipsoid, _ellipsoid_norm\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/interpolate/_bsplines.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _bspl\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/spatial/__init__.py:95: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ckdtree import *\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/spatial/__init__.py:96: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .qhull import *\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/spatial/_spherical_voronoi.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _voronoi\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/spatial/distance.py:122: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hausdorff\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/optimize/_trlib/__init__.py:1: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._trlib import TRLIBQuadraticSubproblem\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/optimize/_numdiff.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._group_columns import group_dense, group_sparse\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/stats/_continuous_distns.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _stats\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/h5py/__init__.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/h5py/__init__.py:45: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import h5a, h5d, h5ds, h5f, h5fd, h5g, h5r, h5s, h5t, h5p, h5z\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/h5py/_hl/group.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .. import h5g, h5i, h5o, h5r, h5t, h5l, h5p\n",
      "Using TensorFlow backend.\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.254 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/sklearn/utils/__init__.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .murmurhash import murmurhash3_32\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/sklearn/utils/extmath.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._logistic_sigmoid import _log_logistic_sigmoid\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/sklearn/utils/extmath.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sparsefuncs_fast import csr_row_norms\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/sklearn/metrics/cluster/supervised.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .expected_mutual_info_fast import expected_mutual_information\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/sklearn/metrics/pairwise.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .pairwise_fast import _chi2_kernel_fast, _sparse_manhattan\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/sklearn/utils/random.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._random import sample_without_replacement\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/sklearn/feature_extraction/hashing.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hashing\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/io/matlab/mio4.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .mio_utils import squeeze_element, chars_to_strings\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/scipy/io/matlab/mio5.py:98: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .mio5_utils import VarReader5\n",
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/sklearn/datasets/svmlight_format.py:25: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._svmlight_format import _load_svmlight_file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 1006 user-define jieba dict success!\n"
     ]
    }
   ],
   "source": [
    "from model_comparer import *\n",
    "from data_converter import load_data\n",
    "from data_converter import down_sample_data\n",
    "import pickle\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "# from __future__ import unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import GridSearchCV   #Perforing grid search\n",
    "from sklearn.externals.joblib import parallel_backend\n",
    "#logger.start('../log/quantize.log', __name__, 'DEBUG')\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "# from __future__ import unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn import metrics   # Additional scklearn functions\n",
    "from sklearn.model_selection import GridSearchCV   #Perforing grid search\n",
    "from sklearn.externals.joblib import parallel_backend\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. train test 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrain_char_v4 = IntentClassify(\n",
    "    [(2, 10, 100, 0.2)], use_rule=False, \n",
    "    token_func=lambda x:FasttextClassifier.fasttext_tokenize(x['text'], char=True, filter_stop_word=True),\n",
    "    pretrain='../conf/fasttext.model.min30_ngram5_d100_it20.vec'\n",
    ")\n",
    "save_model = model_pretrain_char_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 1495 test data form ../data/_train.txt\n",
      "load 504 test data form ../data/_test.txt\n",
      "load 1999 test data form ../data/_total.txt\n",
      "pretrainedVectors: ../conf/fasttext.model.min30_ngram5_d100_it20.vec \n",
      "save model to ./tmp_bin/model_17859_2018-08-14_16-35-41.bin.\n",
      "------\n",
      "FasttextCV failed, errmsg='FasttextClassifier' object has no attribute 'quantize'\n",
      "fit 1 models success!\n"
     ]
    }
   ],
   "source": [
    "#infos = load_data('../data/_total.txt')\n",
    "#down_sample_data(infos, '../data/second_test.txt', '../data/second_train.txt', '../data/second_total.txt', 30,cnt = 10)\n",
    "train_data = load_train_data('../data/_train.txt')\n",
    "test_data = load_train_data('../data/_test.txt')\n",
    "#train_data = [x for x in train_data if x['label'] != u'无意图']\n",
    "total_data = load_train_data('../data/_total.txt')\n",
    "#total_data = [x for x in total_data if x['label'] != u'无意图']\n",
    "label_dict = get_total_fasttext_multi_sen_vec(save_model, train_data, test_data,total_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: u'\\u7f51\\u70b9\\u65e0\\u914d\\u9001',\n",
       " 1: u'\\u5230\\u8d27\\u65f6\\u95f4\\u67e5\\u8be2',\n",
       " 2: u'\\u65e0\\u7269\\u6d41\\u4fe1\\u606f',\n",
       " 3: u'\\u65e0\\u8ba2\\u5355\\u53f7',\n",
       " 4: u'\\u8d27\\u54c1\\u4e22\\u5931',\n",
       " 5: u'\\u65e0\\u610f\\u56fe',\n",
       " 6: u'\\u5feb\\u9012\\u67e5\\u8be2',\n",
       " 7: u'\\u50ac\\u5355',\n",
       " 8: u'\\u67e5\\u8be2\\u4f4d\\u7f6e',\n",
       " 9: u'\\u7269\\u6d41\\u65e0\\u66f4\\u65b0',\n",
       " 10: u'\\u8be2\\u95ee\\u7535\\u8bdd'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ninfos = load_data('../data/taged.txt')\\ndown_sample_data(infos, '../data/second_test.txt', '../data/second_train.txt', '../data/second_total.txt', 5,)\\ntrain_data = load_train_data('../data/second_train.txt')\\ntest_data = load_train_data('../data/second_test.txt')\\ntrain_data = [x for x in train_data if x['label'] != u'\\xe6\\x97\\xa0\\xe6\\x84\\x8f\\xe5\\x9b\\xbe']\\ntotal_data = load_train_data('../data/second_total.txt')\\ntotal_data = [x for x in total_data if x['label'] != u'\\xe6\\x97\\xa0\\xe6\\x84\\x8f\\xe5\\x9b\\xbe']\\nget_total_fasttext_multi_sen_vec(save_model, train_data, test_data,total_data)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "infos = load_data('../data/taged.txt')\n",
    "down_sample_data(infos, '../data/second_test.txt', '../data/second_train.txt', '../data/second_total.txt', 5,)\n",
    "train_data = load_train_data('../data/second_train.txt')\n",
    "test_data = load_train_data('../data/second_test.txt')\n",
    "train_data = [x for x in train_data if x['label'] != u'无意图']\n",
    "total_data = load_train_data('../data/second_total.txt')\n",
    "total_data = [x for x in total_data if x['label'] != u'无意图']\n",
    "get_total_fasttext_multi_sen_vec(save_model, train_data, test_data,total_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('../data/data/sentence_result.txt'))\n",
    "test_x = data['test_x']\n",
    "test_y = data['test_y']\n",
    "train_x = data['train_x']\n",
    "train_y = data['train_y']\n",
    "test_X, train_X = [], []\n",
    "for i in range(len(test_x)):\n",
    "    test_X.append(save_model.get_sentence_vector(test_x[i])[0]) \n",
    "test_X = np.array(test_X)\n",
    "test_y = np.array(test_y, dtype= 'int64')\n",
    "for i in range(len(train_x)):\n",
    "    train_X.append(save_model.get_sentence_vector(train_x[i])[0])\n",
    "train_X = np.array(train_X)\n",
    "train_y = np.array(train_y, dtype= 'int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1495, 100), (1495,), (504, 100), (504,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_y), set(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "dtest = xgb.DMatrix(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "xgb_param['num_class']: 11\n",
      "[0]\ttrain-merror:0.048495+0.00636786\ttest-merror:0.113712+0.0126915\n",
      "[1]\ttrain-merror:0.0245818+0.00336939\ttest-merror:0.0916388+0.0124421\n",
      "[2]\ttrain-merror:0.0103678+0.00319915\ttest-merror:0.0769232+0.00897386\n",
      "[3]\ttrain-merror:0.006689+0.00190637\ttest-merror:0.072241+0.0100556\n",
      "[4]\ttrain-merror:0.0040134+0.000975381\ttest-merror:0.0675586+0.00882323\n",
      "[5]\ttrain-merror:0.0025082+0.00118257\ttest-merror:0.0615386+0.0124422\n",
      "[6]\ttrain-merror:0.0015048+0.000974935\ttest-merror:0.058194+0.0134779\n",
      "[7]\ttrain-merror:0.0010032+0.000819109\ttest-merror:0.0548494+0.0118906\n",
      "[8]\ttrain-merror:0.0006688+0.0003344\ttest-merror:0.052843+0.0112725\n",
      "[9]\ttrain-merror:0.0003344+0.000409555\ttest-merror:0.0494984+0.0106604\n",
      "[10]\ttrain-merror:0.0003344+0.000409555\ttest-merror:0.051505+0.0100556\n",
      "[11]\ttrain-merror:0.0001672+0.0003344\ttest-merror:0.051505+0.0124425\n",
      "[12]\ttrain-merror:0+0\ttest-merror:0.0494984+0.012936\n",
      "[13]\ttrain-merror:0+0\ttest-merror:0.0481608+0.0136429\n",
      "[14]\ttrain-merror:0+0\ttest-merror:0.0468228+0.0128664\n",
      "[15]\ttrain-merror:0+0\ttest-merror:0.045485+0.0134778\n",
      "[16]\ttrain-merror:0+0\ttest-merror:0.045485+0.0141262\n",
      "[17]\ttrain-merror:0+0\ttest-merror:0.045485+0.0117011\n",
      "[18]\ttrain-merror:0+0\ttest-merror:0.0454852+0.0122611\n",
      "[19]\ttrain-merror:0+0\ttest-merror:0.046154+0.0134445\n",
      "[20]\ttrain-merror:0+0\ttest-merror:0.046154+0.0134445\n",
      "[21]\ttrain-merror:0+0\ttest-merror:0.0448162+0.0111124\n",
      "[22]\ttrain-merror:0+0\ttest-merror:0.0454852+0.0122611\n",
      "[23]\ttrain-merror:0+0\ttest-merror:0.046154+0.0134445\n",
      "[24]\ttrain-merror:0+0\ttest-merror:0.045485+0.0141262\n",
      "[25]\ttrain-merror:0+0\ttest-merror:0.045485+0.0141262\n",
      "[26]\ttrain-merror:0+0\ttest-merror:0.044816+0.0124425\n",
      "[27]\ttrain-merror:0+0\ttest-merror:0.046154+0.0116628\n",
      "[28]\ttrain-merror:0+0\ttest-merror:0.043478+0.0111928\n",
      "[29]\ttrain-merror:0+0\ttest-merror:0.0428092+0.0120401\n",
      "[30]\ttrain-merror:0+0\ttest-merror:0.0434782+0.0121511\n",
      "[31]\ttrain-merror:0+0\ttest-merror:0.044147+0.0112725\n",
      "[32]\ttrain-merror:0+0\ttest-merror:0.043478+0.0111928\n",
      "[33]\ttrain-merror:0+0\ttest-merror:0.044147+0.0124064\n",
      "[34]\ttrain-merror:0+0\ttest-merror:0.044147+0.0104484\n",
      "[35]\ttrain-merror:0+0\ttest-merror:0.0441472+0.011853\n",
      "[36]\ttrain-merror:0+0\ttest-merror:0.0441472+0.011853\n",
      "[37]\ttrain-merror:0+0\ttest-merror:0.0441472+0.011853\n",
      "[38]\ttrain-merror:0+0\ttest-merror:0.0434782+0.0105761\n",
      "[39]\ttrain-merror:0+0\ttest-merror:0.0434782+0.0125141\n",
      "[40]\ttrain-merror:0+0\ttest-merror:0.0441472+0.011853\n",
      "[41]\ttrain-merror:0+0\ttest-merror:0.0441472+0.011853\n",
      "[42]\ttrain-merror:0+0\ttest-merror:0.0434782+0.0105761\n",
      "[43]\ttrain-merror:0+0\ttest-merror:0.0428094+0.00931676\n",
      "[44]\ttrain-merror:0+0\ttest-merror:0.0428094+0.00931676\n",
      "[45]\ttrain-merror:0+0\ttest-merror:0.0428094+0.00931676\n",
      "[46]\ttrain-merror:0+0\ttest-merror:0.0428094+0.00931676\n",
      "[47]\ttrain-merror:0+0\ttest-merror:0.0428094+0.00931676\n",
      "[48]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[49]\ttrain-merror:0+0\ttest-merror:0.0428094+0.00931676\n",
      "[50]\ttrain-merror:0+0\ttest-merror:0.0428094+0.00931676\n",
      "[51]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[52]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[53]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[54]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[55]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[56]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[57]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[58]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[59]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[60]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[61]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[62]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[63]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[64]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[65]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[66]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[67]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[68]\ttrain-merror:0+0\ttest-merror:0.0414716+0.00960062\n",
      "[69]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[70]\ttrain-merror:0+0\ttest-merror:0.0414716+0.00960062\n",
      "[71]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[72]\ttrain-merror:0+0\ttest-merror:0.0414716+0.00960062\n",
      "[73]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[74]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[75]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[76]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[77]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[78]\ttrain-merror:0+0\ttest-merror:0.0414716+0.00960062\n",
      "[79]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[80]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[81]\ttrain-merror:0+0\ttest-merror:0.0421406+0.00936466\n",
      "[82]\ttrain-merror:0+0\ttest-merror:0.0414716+0.00960062\n",
      "[83]\ttrain-merror:0+0\ttest-merror:0.0414716+0.00960062\n",
      "[84]\ttrain-merror:0+0\ttest-merror:0.0414716+0.00960062\n",
      "[85]\ttrain-merror:0+0\ttest-merror:0.0414716+0.00960062\n",
      "[86]\ttrain-merror:0+0\ttest-merror:0.0408026+0.00978529\n",
      "[87]\ttrain-merror:0+0\ttest-merror:0.0408026+0.00978529\n",
      "[88]\ttrain-merror:0+0\ttest-merror:0.0408026+0.00978529\n",
      "[89]\ttrain-merror:0+0\ttest-merror:0.0408026+0.00978529\n",
      "[90]\ttrain-merror:0+0\ttest-merror:0.0408026+0.00978529\n",
      "[91]\ttrain-merror:0+0\ttest-merror:0.0408026+0.00978529\n",
      "[92]\ttrain-merror:0+0\ttest-merror:0.0408026+0.00978529\n",
      "[93]\ttrain-merror:0+0\ttest-merror:0.0408026+0.00978529\n",
      "[94]\ttrain-merror:0+0\ttest-merror:0.0408026+0.00978529\n",
      "[95]\ttrain-merror:0+0\ttest-merror:0.0408026+0.00978529\n",
      "[96]\ttrain-merror:0+0\ttest-merror:0.0408026+0.00978529\n",
      "[97]\ttrain-merror:0+0\ttest-merror:0.0408026+0.00978529\n",
      "[98]\ttrain-merror:0+0\ttest-merror:0.0408026+0.00978529\n",
      "[99]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[100]\ttrain-merror:0+0\ttest-merror:0.0401336+0.00846091\n",
      "[101]\ttrain-merror:0+0\ttest-merror:0.0401336+0.00846091\n",
      "[102]\ttrain-merror:0+0\ttest-merror:0.0401336+0.00846091\n",
      "[103]\ttrain-merror:0+0\ttest-merror:0.0401336+0.00846091\n",
      "[104]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[105]\ttrain-merror:0+0\ttest-merror:0.0401336+0.00846091\n",
      "[106]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[107]\ttrain-merror:0+0\ttest-merror:0.0401336+0.00846091\n",
      "[108]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[109]\ttrain-merror:0+0\ttest-merror:0.0401336+0.00846091\n",
      "[110]\ttrain-merror:0+0\ttest-merror:0.0401336+0.00846091\n",
      "[111]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[112]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[113]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[114]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[115]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[116]\ttrain-merror:0+0\ttest-merror:0.038796+0.00750844\n",
      "[117]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[118]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[119]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[120]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[121]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[122]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[123]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[124]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[125]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[126]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[127]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[128]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[129]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[130]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[131]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[132]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[133]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[134]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[135]\ttrain-merror:0+0\ttest-merror:0.0401338+0.0101444\n",
      "[136]\ttrain-merror:0+0\ttest-merror:0.0401338+0.0101444\n",
      "[137]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[138]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[139]\ttrain-merror:0+0\ttest-merror:0.0401338+0.0101444\n",
      "[140]\ttrain-merror:0+0\ttest-merror:0.0401338+0.0101444\n",
      "[141]\ttrain-merror:0+0\ttest-merror:0.0401338+0.0101444\n",
      "[142]\ttrain-merror:0+0\ttest-merror:0.0401338+0.0101444\n",
      "[143]\ttrain-merror:0+0\ttest-merror:0.0401338+0.0101444\n",
      "[144]\ttrain-merror:0+0\ttest-merror:0.0401338+0.0101444\n",
      "[145]\ttrain-merror:0+0\ttest-merror:0.0401338+0.0101444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146]\ttrain-merror:0+0\ttest-merror:0.0401338+0.0101444\n",
      "[147]\ttrain-merror:0+0\ttest-merror:0.0401338+0.0101444\n",
      "[148]\ttrain-merror:0+0\ttest-merror:0.0401338+0.0101444\n",
      "[149]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[150]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[151]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[152]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[153]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[154]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[155]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[156]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[157]\ttrain-merror:0+0\ttest-merror:0.0401338+0.0101444\n",
      "[158]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[159]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[160]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[161]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[162]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[163]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[164]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "[165]\ttrain-merror:0+0\ttest-merror:0.0394648+0.00882326\n",
      "cvresult:\n",
      "\t      test-merror-mean  test-merror-std  train-merror-mean  train-merror-std\n",
      "0            0.113712         0.012692           0.048495          0.006368\n",
      "1            0.091639         0.012442           0.024582          0.003369\n",
      "2            0.076923         0.008974           0.010368          0.003199\n",
      "3            0.072241         0.010056           0.006689          0.001906\n",
      "4            0.067559         0.008823           0.004013          0.000975\n",
      "5            0.061539         0.012442           0.002508          0.001183\n",
      "6            0.058194         0.013478           0.001505          0.000975\n",
      "7            0.054849         0.011891           0.001003          0.000819\n",
      "8            0.052843         0.011273           0.000669          0.000334\n",
      "9            0.049498         0.010660           0.000334          0.000410\n",
      "10           0.051505         0.010056           0.000334          0.000410\n",
      "11           0.051505         0.012442           0.000167          0.000334\n",
      "12           0.049498         0.012936           0.000000          0.000000\n",
      "13           0.048161         0.013643           0.000000          0.000000\n",
      "14           0.046823         0.012866           0.000000          0.000000\n",
      "15           0.045485         0.013478           0.000000          0.000000\n",
      "16           0.045485         0.014126           0.000000          0.000000\n",
      "17           0.045485         0.011701           0.000000          0.000000\n",
      "18           0.045485         0.012261           0.000000          0.000000\n",
      "19           0.046154         0.013445           0.000000          0.000000\n",
      "20           0.046154         0.013445           0.000000          0.000000\n",
      "21           0.044816         0.011112           0.000000          0.000000\n",
      "22           0.045485         0.012261           0.000000          0.000000\n",
      "23           0.046154         0.013445           0.000000          0.000000\n",
      "24           0.045485         0.014126           0.000000          0.000000\n",
      "25           0.045485         0.014126           0.000000          0.000000\n",
      "26           0.044816         0.012442           0.000000          0.000000\n",
      "27           0.046154         0.011663           0.000000          0.000000\n",
      "28           0.043478         0.011193           0.000000          0.000000\n",
      "29           0.042809         0.012040           0.000000          0.000000\n",
      "..                ...              ...                ...               ...\n",
      "87           0.040803         0.009785           0.000000          0.000000\n",
      "88           0.040803         0.009785           0.000000          0.000000\n",
      "89           0.040803         0.009785           0.000000          0.000000\n",
      "90           0.040803         0.009785           0.000000          0.000000\n",
      "91           0.040803         0.009785           0.000000          0.000000\n",
      "92           0.040803         0.009785           0.000000          0.000000\n",
      "93           0.040803         0.009785           0.000000          0.000000\n",
      "94           0.040803         0.009785           0.000000          0.000000\n",
      "95           0.040803         0.009785           0.000000          0.000000\n",
      "96           0.040803         0.009785           0.000000          0.000000\n",
      "97           0.040803         0.009785           0.000000          0.000000\n",
      "98           0.040803         0.009785           0.000000          0.000000\n",
      "99           0.039465         0.008823           0.000000          0.000000\n",
      "100          0.040134         0.008461           0.000000          0.000000\n",
      "101          0.040134         0.008461           0.000000          0.000000\n",
      "102          0.040134         0.008461           0.000000          0.000000\n",
      "103          0.040134         0.008461           0.000000          0.000000\n",
      "104          0.039465         0.008823           0.000000          0.000000\n",
      "105          0.040134         0.008461           0.000000          0.000000\n",
      "106          0.039465         0.008823           0.000000          0.000000\n",
      "107          0.040134         0.008461           0.000000          0.000000\n",
      "108          0.039465         0.008823           0.000000          0.000000\n",
      "109          0.040134         0.008461           0.000000          0.000000\n",
      "110          0.040134         0.008461           0.000000          0.000000\n",
      "111          0.039465         0.008823           0.000000          0.000000\n",
      "112          0.039465         0.008823           0.000000          0.000000\n",
      "113          0.039465         0.008823           0.000000          0.000000\n",
      "114          0.039465         0.008823           0.000000          0.000000\n",
      "115          0.039465         0.008823           0.000000          0.000000\n",
      "116          0.038796         0.007508           0.000000          0.000000\n",
      "\n",
      "[117 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Logloss : 0.003471103307651521\n",
      "Accuracy : 1\n",
      "classification_report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        29\n",
      "          1       1.00      1.00      1.00        74\n",
      "          2       1.00      1.00      1.00        19\n",
      "          3       1.00      1.00      1.00        10\n",
      "          4       1.00      1.00      1.00        68\n",
      "          5       1.00      1.00      1.00      1031\n",
      "          6       1.00      1.00      1.00        20\n",
      "          7       1.00      1.00      1.00       132\n",
      "          8       1.00      1.00      1.00        30\n",
      "          9       1.00      1.00      1.00        46\n",
      "         10       1.00      1.00      1.00        36\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1495\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAEPCAYAAACEFZjFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJGlAdqIlSZKkAf3/ChrbmHxsgpMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def modelfit(alg, X, y, useTrainCV=True, cv_folds=5, early_stopping_rounds=50, verbose_eval=True):\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgb_param['num_class'] = len(set(y))\n",
    "        print(len(set(y)))\n",
    "        print(\"xgb_param['num_class']:\",xgb_param['num_class'])\n",
    "        xgtrain = xgb.DMatrix(X, label=y)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "                          metrics='merror', early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose_eval)\n",
    "        print('cvresult:\\n\\t', cvresult)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X, y, eval_metric='merror')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X)\n",
    "    dtrain_predprob = alg.predict_proba(X)\n",
    "    #Print model report:\n",
    "    print('\\nModel Report')\n",
    "    print('Logloss : %s' % (metrics.log_loss(y, dtrain_predprob, eps=1e-15)))\n",
    "    print('Accuracy : %.4g' % metrics.accuracy_score(y, dtrain_predictions))\n",
    "    print('classification_report :\\n%s' % metrics.classification_report(y, dtrain_predictions))\n",
    "#     print(dir(alg))\n",
    "    _booster = alg.get_booster()\n",
    "    _score = _booster.get_fscore()\n",
    "    feat_imp = pd.Series(_score).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "#     return cvresult\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.5,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective='multi:softprob',\n",
    " nthread=20,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, train_X, train_y)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "xgb_param['num_class']: 11\n",
      "[0]\ttrain-merror:0.048495+0.00636786\ttest-merror:0.113712+0.0126915\n",
      "[1]\ttrain-merror:0.0173916+0.00250281\ttest-merror:0.105685+0.00688679\n",
      "[2]\ttrain-merror:0.0035116+0.00143873\ttest-merror:0.08495+0.00500527\n",
      "[3]\ttrain-merror:0.001672+0.000528733\ttest-merror:0.0822746+0.0107023\n",
      "[4]\ttrain-merror:0.0006688+0.0003344\ttest-merror:0.0769234+0.0115856\n",
      "[5]\ttrain-merror:0.0005016+0.000409555\ttest-merror:0.078261+0.0115081\n",
      "[6]\ttrain-merror:0.0001672+0.0003344\ttest-merror:0.076923+0.0117771\n",
      "[7]\ttrain-merror:0.0001672+0.0003344\ttest-merror:0.0735786+0.0107856\n",
      "[8]\ttrain-merror:0+0\ttest-merror:0.0735788+0.0101442\n",
      "[9]\ttrain-merror:0+0\ttest-merror:0.0722408+0.0115082\n",
      "[10]\ttrain-merror:0+0\ttest-merror:0.0729098+0.0110722\n",
      "[11]\ttrain-merror:0+0\ttest-merror:0.0715718+0.0115082\n",
      "[12]\ttrain-merror:0+0\ttest-merror:0.070903+0.0116626\n",
      "[13]\ttrain-merror:0+0\ttest-merror:0.0709032+0.0125852\n",
      "[14]\ttrain-merror:0+0\ttest-merror:0.0688964+0.0117011\n",
      "[15]\ttrain-merror:0+0\ttest-merror:0.070234+0.0126915\n",
      "[16]\ttrain-merror:0+0\ttest-merror:0.0702342+0.0109912\n",
      "[17]\ttrain-merror:0+0\ttest-merror:0.0688964+0.0124423\n",
      "[18]\ttrain-merror:0+0\ttest-merror:0.0695654+0.0125853\n",
      "[19]\ttrain-merror:0+0\ttest-merror:0.0702342+0.011391\n",
      "[20]\ttrain-merror:0+0\ttest-merror:0.070903+0.0120401\n",
      "[21]\ttrain-merror:0+0\ttest-merror:0.0702342+0.0121511\n",
      "[22]\ttrain-merror:0+0\ttest-merror:0.0722408+0.0115082\n",
      "[23]\ttrain-merror:0+0\ttest-merror:0.070234+0.0126915\n",
      "[24]\ttrain-merror:0+0\ttest-merror:0.070903+0.0127618\n",
      "[25]\ttrain-merror:0+0\ttest-merror:0.0715718+0.0131415\n",
      "[26]\ttrain-merror:0+0\ttest-merror:0.0709032+0.0114694\n",
      "[27]\ttrain-merror:0+0\ttest-merror:0.0702342+0.0109912\n",
      "[28]\ttrain-merror:0+0\ttest-merror:0.0688964+0.0117011\n",
      "[29]\ttrain-merror:0+0\ttest-merror:0.0688964+0.0117011\n",
      "[30]\ttrain-merror:0+0\ttest-merror:0.070903+0.0104487\n",
      "[31]\ttrain-merror:0+0\ttest-merror:0.0702342+0.0109912\n",
      "[32]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0116628\n",
      "[33]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0116628\n",
      "[34]\ttrain-merror:0+0\ttest-merror:0.0702342+0.0121511\n",
      "[35]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0116628\n",
      "[36]\ttrain-merror:0+0\ttest-merror:0.0695654+0.0106606\n",
      "[37]\ttrain-merror:0+0\ttest-merror:0.0688964+0.0113123\n",
      "[38]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0116628\n",
      "[39]\ttrain-merror:0+0\ttest-merror:0.070903+0.0104487\n",
      "[40]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0116628\n",
      "[41]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[42]\ttrain-merror:0+0\ttest-merror:0.0702342+0.0117771\n",
      "[43]\ttrain-merror:0+0\ttest-merror:0.070234+0.0126915\n",
      "[44]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0134446\n",
      "[45]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[46]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[47]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[48]\ttrain-merror:0+0\ttest-merror:0.0688964+0.0117011\n",
      "[49]\ttrain-merror:0+0\ttest-merror:0.0688964+0.0117011\n",
      "[50]\ttrain-merror:0+0\ttest-merror:0.0688964+0.0117011\n",
      "[51]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0116628\n",
      "[52]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[53]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[54]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[55]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[56]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[57]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[58]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[59]\ttrain-merror:0+0\ttest-merror:0.0688962+0.0129705\n",
      "[60]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0124062\n",
      "[61]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0116628\n",
      "[62]\ttrain-merror:0+0\ttest-merror:0.0702342+0.0138706\n",
      "[63]\ttrain-merror:0+0\ttest-merror:0.0688966+0.0126208\n",
      "[64]\ttrain-merror:0+0\ttest-merror:0.0709032+0.0132771\n",
      "[65]\ttrain-merror:0+0\ttest-merror:0.0709032+0.0125852\n",
      "[66]\ttrain-merror:0+0\ttest-merror:0.071572+0.0124422\n",
      "[67]\ttrain-merror:0+0\ttest-merror:0.0702342+0.0138706\n",
      "[68]\ttrain-merror:0+0\ttest-merror:0.070234+0.0126915\n",
      "[69]\ttrain-merror:0+0\ttest-merror:0.0702342+0.0138706\n",
      "[70]\ttrain-merror:0+0\ttest-merror:0.071572+0.0124422\n",
      "[71]\ttrain-merror:0+0\ttest-merror:0.0702342+0.0132098\n",
      "[72]\ttrain-merror:0+0\ttest-merror:0.070234+0.0126915\n",
      "[73]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0134448\n",
      "[74]\ttrain-merror:0+0\ttest-merror:0.070903+0.0120401\n",
      "[75]\ttrain-merror:0+0\ttest-merror:0.070234+0.0126915\n",
      "[76]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[77]\ttrain-merror:0+0\ttest-merror:0.0702342+0.0121511\n",
      "[78]\ttrain-merror:0+0\ttest-merror:0.0702342+0.0121511\n",
      "[79]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[80]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[81]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[82]\ttrain-merror:0+0\ttest-merror:0.070903+0.0120401\n",
      "[83]\ttrain-merror:0+0\ttest-merror:0.0702342+0.0117771\n",
      "[84]\ttrain-merror:0+0\ttest-merror:0.070234+0.0126915\n",
      "[85]\ttrain-merror:0+0\ttest-merror:0.070903+0.0120401\n",
      "[86]\ttrain-merror:0+0\ttest-merror:0.070234+0.0126915\n",
      "[87]\ttrain-merror:0+0\ttest-merror:0.070234+0.0126915\n",
      "[88]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[89]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[90]\ttrain-merror:0+0\ttest-merror:0.070234+0.0126915\n",
      "[91]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[92]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[93]\ttrain-merror:0+0\ttest-merror:0.071572+0.0124422\n",
      "[94]\ttrain-merror:0+0\ttest-merror:0.070903+0.0120401\n",
      "[95]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[96]\ttrain-merror:0+0\ttest-merror:0.070903+0.0120401\n",
      "[97]\ttrain-merror:0+0\ttest-merror:0.0702342+0.0117771\n",
      "[98]\ttrain-merror:0+0\ttest-merror:0.070903+0.0120401\n",
      "[99]\ttrain-merror:0+0\ttest-merror:0.070234+0.0126915\n",
      "[100]\ttrain-merror:0+0\ttest-merror:0.070903+0.0120401\n",
      "[101]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0127618\n",
      "[102]\ttrain-merror:0+0\ttest-merror:0.070234+0.0126915\n",
      "[103]\ttrain-merror:0+0\ttest-merror:0.070903+0.0131078\n",
      "[104]\ttrain-merror:0+0\ttest-merror:0.070903+0.0131078\n",
      "[105]\ttrain-merror:0+0\ttest-merror:0.0695654+0.0139349\n",
      "[106]\ttrain-merror:0+0\ttest-merror:0.0695652+0.0147159\n",
      "[107]\ttrain-merror:0+0\ttest-merror:0.0688964+0.0147462\n",
      "[108]\ttrain-merror:0+0\ttest-merror:0.0688962+0.0142838\n",
      "cvresult:\n",
      "\t     test-merror-mean  test-merror-std  train-merror-mean  train-merror-std\n",
      "0           0.113712         0.012692           0.048495          0.006368\n",
      "1           0.105685         0.006887           0.017392          0.002503\n",
      "2           0.084950         0.005005           0.003512          0.001439\n",
      "3           0.082275         0.010702           0.001672          0.000529\n",
      "4           0.076923         0.011586           0.000669          0.000334\n",
      "5           0.078261         0.011508           0.000502          0.000410\n",
      "6           0.076923         0.011777           0.000167          0.000334\n",
      "7           0.073579         0.010786           0.000167          0.000334\n",
      "8           0.073579         0.010144           0.000000          0.000000\n",
      "9           0.072241         0.011508           0.000000          0.000000\n",
      "10          0.072910         0.011072           0.000000          0.000000\n",
      "11          0.071572         0.011508           0.000000          0.000000\n",
      "12          0.070903         0.011663           0.000000          0.000000\n",
      "13          0.070903         0.012585           0.000000          0.000000\n",
      "14          0.068896         0.011701           0.000000          0.000000\n",
      "15          0.070234         0.012691           0.000000          0.000000\n",
      "16          0.070234         0.010991           0.000000          0.000000\n",
      "17          0.068896         0.012442           0.000000          0.000000\n",
      "18          0.069565         0.012585           0.000000          0.000000\n",
      "19          0.070234         0.011391           0.000000          0.000000\n",
      "20          0.070903         0.012040           0.000000          0.000000\n",
      "21          0.070234         0.012151           0.000000          0.000000\n",
      "22          0.072241         0.011508           0.000000          0.000000\n",
      "23          0.070234         0.012691           0.000000          0.000000\n",
      "24          0.070903         0.012762           0.000000          0.000000\n",
      "25          0.071572         0.013142           0.000000          0.000000\n",
      "26          0.070903         0.011469           0.000000          0.000000\n",
      "27          0.070234         0.010991           0.000000          0.000000\n",
      "28          0.068896         0.011701           0.000000          0.000000\n",
      "29          0.068896         0.011701           0.000000          0.000000\n",
      "30          0.070903         0.010449           0.000000          0.000000\n",
      "31          0.070234         0.010991           0.000000          0.000000\n",
      "32          0.069565         0.011663           0.000000          0.000000\n",
      "33          0.069565         0.011663           0.000000          0.000000\n",
      "34          0.070234         0.012151           0.000000          0.000000\n",
      "35          0.069565         0.011663           0.000000          0.000000\n",
      "36          0.069565         0.010661           0.000000          0.000000\n",
      "37          0.068896         0.011312           0.000000          0.000000\n",
      "38          0.069565         0.011663           0.000000          0.000000\n",
      "39          0.070903         0.010449           0.000000          0.000000\n",
      "40          0.069565         0.011663           0.000000          0.000000\n",
      "41          0.069565         0.012762           0.000000          0.000000\n",
      "42          0.070234         0.011777           0.000000          0.000000\n",
      "43          0.070234         0.012691           0.000000          0.000000\n",
      "44          0.069565         0.013445           0.000000          0.000000\n",
      "45          0.069565         0.012762           0.000000          0.000000\n",
      "46          0.069565         0.012762           0.000000          0.000000\n",
      "47          0.069565         0.012762           0.000000          0.000000\n",
      "48          0.068896         0.011701           0.000000          0.000000\n",
      "49          0.068896         0.011701           0.000000          0.000000\n",
      "50          0.068896         0.011701           0.000000          0.000000\n",
      "51          0.069565         0.011663           0.000000          0.000000\n",
      "52          0.069565         0.012762           0.000000          0.000000\n",
      "53          0.069565         0.012762           0.000000          0.000000\n",
      "54          0.069565         0.012762           0.000000          0.000000\n",
      "55          0.069565         0.012762           0.000000          0.000000\n",
      "56          0.069565         0.012762           0.000000          0.000000\n",
      "57          0.069565         0.012762           0.000000          0.000000\n",
      "58          0.069565         0.012762           0.000000          0.000000\n",
      "59          0.068896         0.012970           0.000000          0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/works/data/tools/miniconda2/envs/tfenv.v1.2/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Logloss : 0.0032917623797778907\n",
      "Accuracy : 1\n",
      "classification_report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        29\n",
      "          1       1.00      1.00      1.00        74\n",
      "          2       1.00      1.00      1.00        19\n",
      "          3       1.00      1.00      1.00        10\n",
      "          4       1.00      1.00      1.00        68\n",
      "          5       1.00      1.00      1.00      1031\n",
      "          6       1.00      1.00      1.00        20\n",
      "          7       1.00      1.00      1.00       132\n",
      "          8       1.00      1.00      1.00        30\n",
      "          9       1.00      1.00      1.00        46\n",
      "         10       1.00      1.00      1.00        36\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1495\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAEPCAYAAACEFZjFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =1.5,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective='multi:softprob',\n",
    " nthread=20,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV] max_depth=3, min_child_weight=1 .................................[CV] max_depth=3, min_child_weight=1 .................................\n",
      "\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV] ...... max_depth=3, min_child_weight=3, score=0.96, total=   1.4s\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV]  max_depth=3, min_child_weight=5, score=0.976897689769, total=   1.5s\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV]  max_depth=3, min_child_weight=3, score=0.976271186441, total=   1.5s\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV]  max_depth=3, min_child_weight=3, score=0.963696369637, total=   1.6s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV]  max_depth=3, min_child_weight=3, score=0.973244147157, total=   1.6s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV]  max_depth=3, min_child_weight=1, score=0.959731543624, total=   1.7s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV]  max_depth=3, min_child_weight=1, score=0.979933110368, total=   1.7s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV]  max_depth=3, min_child_weight=1, score=0.973333333333, total=   1.7s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV]  max_depth=3, min_child_weight=3, score=0.939597315436, total=   1.7s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV]  max_depth=3, min_child_weight=1, score=0.979661016949, total=   1.8s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV]  max_depth=3, min_child_weight=5, score=0.966666666667, total=   1.8s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV]  max_depth=3, min_child_weight=1, score=0.963696369637, total=   1.9s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV]  max_depth=3, min_child_weight=5, score=0.946308724832, total=   1.4s\n",
      "[CV] max_depth=5, min_child_weight=3 .................................\n",
      "[CV]  max_depth=3, min_child_weight=5, score=0.966101694915, total=   1.4s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV]  max_depth=3, min_child_weight=5, score=0.976588628763, total=   1.6s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV]  max_depth=5, min_child_weight=3, score=0.973244147157, total=   1.6s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV]  max_depth=5, min_child_weight=1, score=0.976588628763, total=   1.7s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV]  max_depth=5, min_child_weight=1, score=0.979661016949, total=   1.7s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV]  max_depth=5, min_child_weight=1, score=0.957095709571, total=   1.9s\n",
      "[CV] max_depth=7, min_child_weight=1 .................................\n",
      "[CV]  max_depth=5, min_child_weight=3, score=0.957095709571, total=   1.8s\n",
      "[CV] max_depth=7, min_child_weight=1 .................................\n",
      "[CV]  max_depth=5, min_child_weight=1, score=0.963087248322, total=   1.9s\n",
      "[CV] max_depth=7, min_child_weight=1 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    3.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, min_child_weight=1, score=0.973333333333, total=   2.0s\n",
      "[CV] max_depth=7, min_child_weight=1 .................................\n",
      "[CV] ...... max_depth=5, min_child_weight=3, score=0.97, total=   1.9s\n",
      "[CV] max_depth=7, min_child_weight=1 .................................\n",
      "[CV]  max_depth=5, min_child_weight=3, score=0.953020134228, total=   1.9s\n",
      "[CV] max_depth=7, min_child_weight=3 .................................\n",
      "[CV]  max_depth=5, min_child_weight=5, score=0.966666666667, total=   1.5s\n",
      "[CV] max_depth=7, min_child_weight=3 .................................\n",
      "[CV]  max_depth=5, min_child_weight=3, score=0.976271186441, total=   1.6s\n",
      "[CV] max_depth=7, min_child_weight=3 .................................\n",
      "[CV]  max_depth=5, min_child_weight=5, score=0.963696369637, total=   1.5s\n",
      "[CV] max_depth=7, min_child_weight=3 .................................\n",
      "[CV]  max_depth=5, min_child_weight=5, score=0.979933110368, total=   1.4s\n",
      "[CV] max_depth=7, min_child_weight=3 .................................\n",
      "[CV]  max_depth=5, min_child_weight=5, score=0.942953020134, total=   1.7s\n",
      "[CV] max_depth=7, min_child_weight=5 .................................\n",
      "[CV]  max_depth=5, min_child_weight=5, score=0.976271186441, total=   1.7s\n",
      "[CV] max_depth=7, min_child_weight=5 .................................\n",
      "[CV]  max_depth=7, min_child_weight=1, score=0.957095709571, total=   1.8s\n",
      "[CV] max_depth=7, min_child_weight=5 .................................\n",
      "[CV]  max_depth=7, min_child_weight=1, score=0.976666666667, total=   1.9s\n",
      "[CV] max_depth=7, min_child_weight=5 .................................\n",
      "[CV]  max_depth=7, min_child_weight=1, score=0.973244147157, total=   1.9s\n",
      "[CV] max_depth=7, min_child_weight=5 .................................\n",
      "[CV]  max_depth=7, min_child_weight=3, score=0.960396039604, total=   1.7s\n",
      "[CV] max_depth=9, min_child_weight=1 .................................\n",
      "[CV]  max_depth=7, min_child_weight=1, score=0.959731543624, total=   2.0s\n",
      "[CV] max_depth=9, min_child_weight=1 .................................\n",
      "[CV]  max_depth=7, min_child_weight=1, score=0.979661016949, total=   2.0s\n",
      "[CV] max_depth=9, min_child_weight=1 .................................\n",
      "[CV]  max_depth=7, min_child_weight=3, score=0.94966442953, total=   1.4s\n",
      "[CV] max_depth=9, min_child_weight=1 .................................\n",
      "[CV]  max_depth=7, min_child_weight=3, score=0.976588628763, total=   1.6s\n",
      "[CV] max_depth=9, min_child_weight=1 .................................\n",
      "[CV] ...... max_depth=7, min_child_weight=3, score=0.97, total=   1.8s\n",
      "[CV] max_depth=9, min_child_weight=3 .................................\n",
      "[CV]  max_depth=7, min_child_weight=3, score=0.979661016949, total=   1.7s\n",
      "[CV] max_depth=9, min_child_weight=3 .................................\n",
      "[CV]  max_depth=7, min_child_weight=5, score=0.970297029703, total=   1.7s\n",
      "[CV] max_depth=9, min_child_weight=3 .................................\n",
      "[CV] ...... max_depth=7, min_child_weight=5, score=0.97, total=   1.9s\n",
      "[CV] max_depth=9, min_child_weight=3 .................................\n",
      "[CV]  max_depth=7, min_child_weight=5, score=0.979933110368, total=   1.8s\n",
      "[CV] max_depth=9, min_child_weight=3 .................................\n",
      "[CV]  max_depth=9, min_child_weight=1, score=0.960396039604, total=   1.7s\n",
      "[CV] max_depth=9, min_child_weight=5 .................................\n",
      "[CV]  max_depth=7, min_child_weight=5, score=0.93288590604, total=   1.9s\n",
      "[CV] max_depth=9, min_child_weight=5 .................................\n",
      "[CV]  max_depth=7, min_child_weight=5, score=0.962711864407, total=   1.9s\n",
      "[CV] max_depth=9, min_child_weight=5 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  45 out of  60 | elapsed:    7.5s remaining:    2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=9, min_child_weight=1, score=0.976666666667, total=   2.0s\n",
      "[CV] max_depth=9, min_child_weight=5 .................................\n",
      "[CV]  max_depth=9, min_child_weight=1, score=0.973244147157, total=   1.9s\n",
      "[CV] max_depth=9, min_child_weight=5 .................................\n",
      "[CV]  max_depth=9, min_child_weight=1, score=0.959731543624, total=   1.8s\n",
      "[CV]  max_depth=9, min_child_weight=1, score=0.976271186441, total=   1.7s\n",
      "[CV]  max_depth=9, min_child_weight=3, score=0.963696369637, total=   1.7s\n",
      "[CV]  max_depth=9, min_child_weight=3, score=0.973333333333, total=   1.6s\n",
      "[CV]  max_depth=9, min_child_weight=3, score=0.966555183946, total=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  53 out of  60 | elapsed:    8.6s remaining:    1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=9, min_child_weight=3, score=0.972881355932, total=   1.5s\n",
      "[CV]  max_depth=9, min_child_weight=5, score=0.96699669967, total=   1.6s\n",
      "[CV]  max_depth=9, min_child_weight=5, score=0.979933110368, total=   1.4s\n",
      "[CV]  max_depth=9, min_child_weight=3, score=0.946308724832, total=   1.7s\n",
      "[CV] ...... max_depth=9, min_child_weight=5, score=0.97, total=   1.6s\n",
      "[CV]  max_depth=9, min_child_weight=5, score=0.976271186441, total=   1.4s\n",
      "[CV]  max_depth=9, min_child_weight=5, score=0.959731543624, total=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  60 out of  60 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.97127, std: 0.00825, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       "  mean: 0.96256, std: 0.01294, params: {'max_depth': 3, 'min_child_weight': 3},\n",
       "  mean: 0.96651, std: 0.01112, params: {'max_depth': 3, 'min_child_weight': 5},\n",
       "  mean: 0.96995, std: 0.00851, params: {'max_depth': 5, 'min_child_weight': 1},\n",
       "  mean: 0.96593, std: 0.00918, params: {'max_depth': 5, 'min_child_weight': 3},\n",
       "  mean: 0.96590, std: 0.01293, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       "  mean: 0.96928, std: 0.00914, params: {'max_depth': 7, 'min_child_weight': 1},\n",
       "  mean: 0.96726, std: 0.01100, params: {'max_depth': 7, 'min_child_weight': 3},\n",
       "  mean: 0.96317, std: 0.01610, params: {'max_depth': 7, 'min_child_weight': 5},\n",
       "  mean: 0.96926, std: 0.00761, params: {'max_depth': 9, 'min_child_weight': 1},\n",
       "  mean: 0.96455, std: 0.00984, params: {'max_depth': 9, 'min_child_weight': 3},\n",
       "  mean: 0.97059, std: 0.00708, params: {'max_depth': 9, 'min_child_weight': 5}],\n",
       " {'max_depth': 3, 'min_child_weight': 1},\n",
       " 0.9712710747823007)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "xgbc = XGBClassifier(\n",
    "    learning_rate =0.5,\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='multi:softprob',\n",
    "    nthread=4, \n",
    "    scale_pos_weight=1, \n",
    "    seed=27)\n",
    "\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator = xgbc, \n",
    "    param_grid = param_test1,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=12,\n",
    "    iid=False,\n",
    "    cv=5,\n",
    "    verbose=8)\n",
    "with parallel_backend('threading'):\n",
    "    gsearch1.fit(train_X, train_y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] max_depth=2, min_child_weight=1 .................................\n",
      "[CV] max_depth=2, min_child_weight=1 .................................\n",
      "[CV] max_depth=2, min_child_weight=1 .................................\n",
      "[CV] max_depth=2, min_child_weight=1 .................................\n",
      "[CV]  max_depth=2, min_child_weight=1, score=0.973333333333, total=   0.7s\n",
      "[CV] max_depth=2, min_child_weight=1 .................................\n",
      "[CV]  max_depth=2, min_child_weight=1, score=0.969899665552, total=   0.7s\n",
      "[CV] max_depth=2, min_child_weight=2 .................................\n",
      "[CV]  max_depth=2, min_child_weight=1, score=0.959731543624, total=   0.7s\n",
      "[CV] max_depth=2, min_child_weight=2 .................................\n",
      "[CV]  max_depth=2, min_child_weight=1, score=0.963696369637, total=   0.9s\n",
      "[CV] max_depth=2, min_child_weight=2 .................................\n",
      "[CV] ...... max_depth=2, min_child_weight=2, score=0.97, total=   0.6s\n",
      "[CV] max_depth=2, min_child_weight=2 .................................\n",
      "[CV]  max_depth=2, min_child_weight=1, score=0.979661016949, total=   0.7s\n",
      "[CV] max_depth=2, min_child_weight=2 .................................\n",
      "[CV]  max_depth=2, min_child_weight=2, score=0.96699669967, total=   0.7s\n",
      "[CV] max_depth=2, min_child_weight=3 .................................\n",
      "[CV]  max_depth=2, min_child_weight=2, score=0.966555183946, total=   0.8s\n",
      "[CV] max_depth=2, min_child_weight=3 .................................\n",
      "[CV]  max_depth=2, min_child_weight=2, score=0.942953020134, total=   0.6s\n",
      "[CV] max_depth=2, min_child_weight=3 .................................\n",
      "[CV]  max_depth=2, min_child_weight=3, score=0.970297029703, total=   0.6s\n",
      "[CV] max_depth=2, min_child_weight=3 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=2, min_child_weight=2, score=0.983050847458, total=   0.7s\n",
      "[CV] max_depth=2, min_child_weight=3 .................................\n",
      "[CV]  max_depth=2, min_child_weight=3, score=0.973333333333, total=   0.8s\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV]  max_depth=2, min_child_weight=3, score=0.973244147157, total=   0.7s\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV]  max_depth=2, min_child_weight=3, score=0.946308724832, total=   0.7s\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV]  max_depth=2, min_child_weight=3, score=0.976271186441, total=   0.7s\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV]  max_depth=3, min_child_weight=1, score=0.963696369637, total=   0.7s\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV]  max_depth=3, min_child_weight=1, score=0.973333333333, total=   0.6s\n",
      "[CV] max_depth=3, min_child_weight=2 .................................\n",
      "[CV]  max_depth=3, min_child_weight=1, score=0.979933110368, total=   0.8s\n",
      "[CV] max_depth=3, min_child_weight=2 .................................\n",
      "[CV]  max_depth=3, min_child_weight=1, score=0.956375838926, total=   0.7s\n",
      "[CV] max_depth=3, min_child_weight=2 .................................\n",
      "[CV]  max_depth=3, min_child_weight=2, score=0.957095709571, total=   0.6s\n",
      "[CV] max_depth=3, min_child_weight=2 .................................\n",
      "[CV]  max_depth=3, min_child_weight=1, score=0.976271186441, total=   0.7s\n",
      "[CV] max_depth=3, min_child_weight=2 .................................\n",
      "[CV]  max_depth=3, min_child_weight=2, score=0.976588628763, total=   0.7s\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n",
      "[CV]  max_depth=3, min_child_weight=2, score=0.966666666667, total=   0.8s\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n",
      "[CV]  max_depth=3, min_child_weight=2, score=0.979661016949, total=   0.6s\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n",
      "[CV]  max_depth=3, min_child_weight=2, score=0.963087248322, total=   0.7s\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n",
      "[CV]  max_depth=3, min_child_weight=3, score=0.960396039604, total=   0.6s\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n",
      "[CV]  max_depth=3, min_child_weight=3, score=0.956666666667, total=   0.7s\n",
      "[CV] max_depth=4, min_child_weight=1 .................................\n",
      "[CV]  max_depth=3, min_child_weight=3, score=0.973244147157, total=   0.6s\n",
      "[CV] max_depth=4, min_child_weight=1 .................................\n",
      "[CV]  max_depth=3, min_child_weight=3, score=0.939597315436, total=   0.7s\n",
      "[CV] max_depth=4, min_child_weight=1 .................................\n",
      "[CV]  max_depth=3, min_child_weight=3, score=0.976271186441, total=   0.6s\n",
      "[CV] max_depth=4, min_child_weight=1 .................................\n",
      "[CV]  max_depth=4, min_child_weight=1, score=0.953795379538, total=   0.8s\n",
      "[CV] max_depth=4, min_child_weight=1 .................................\n",
      "[CV]  max_depth=4, min_child_weight=1, score=0.976666666667, total=   0.7s\n",
      "[CV] max_depth=4, min_child_weight=2 .................................\n",
      "[CV]  max_depth=4, min_child_weight=1, score=0.976588628763, total=   0.7s\n",
      "[CV] max_depth=4, min_child_weight=2 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    6.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, min_child_weight=1, score=0.94966442953, total=   0.9s\n",
      "[CV] max_depth=4, min_child_weight=2 .................................\n",
      "[CV]  max_depth=4, min_child_weight=2, score=0.973597359736, total=   0.6s\n",
      "[CV] max_depth=4, min_child_weight=2 .................................\n",
      "[CV]  max_depth=4, min_child_weight=1, score=0.979661016949, total=   0.8s\n",
      "[CV] max_depth=4, min_child_weight=2 .................................\n",
      "[CV]  max_depth=4, min_child_weight=2, score=0.973333333333, total=   0.8s\n",
      "[CV] max_depth=4, min_child_weight=3 .................................\n",
      "[CV]  max_depth=4, min_child_weight=2, score=0.976588628763, total=   0.8s\n",
      "[CV] max_depth=4, min_child_weight=3 .................................\n",
      "[CV]  max_depth=4, min_child_weight=2, score=0.956375838926, total=   0.9s\n",
      "[CV] max_depth=4, min_child_weight=3 .................................\n",
      "[CV]  max_depth=4, min_child_weight=2, score=0.976271186441, total=   0.8s\n",
      "[CV] max_depth=4, min_child_weight=3 .................................\n",
      "[CV]  max_depth=4, min_child_weight=3, score=0.96699669967, total=   0.8s\n",
      "[CV] max_depth=4, min_child_weight=3 .................................\n",
      "[CV]  max_depth=4, min_child_weight=3, score=0.973333333333, total=   0.7s\n",
      "[CV]  max_depth=4, min_child_weight=3, score=0.94966442953, total=   0.7s\n",
      "[CV]  max_depth=4, min_child_weight=3, score=0.969899665552, total=   0.9s\n",
      "[CV]  max_depth=4, min_child_weight=3, score=0.979661016949, total=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  45 out of  45 | elapsed:    8.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.96926, std: 0.00703, params: {'max_depth': 2, 'min_child_weight': 1},\n",
       "  mean: 0.96591, std: 0.01295, params: {'max_depth': 2, 'min_child_weight': 2},\n",
       "  mean: 0.96789, std: 0.01096, params: {'max_depth': 2, 'min_child_weight': 3},\n",
       "  mean: 0.96992, std: 0.00865, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       "  mean: 0.96862, std: 0.00840, params: {'max_depth': 3, 'min_child_weight': 2},\n",
       "  mean: 0.96124, std: 0.01312, params: {'max_depth': 3, 'min_child_weight': 3},\n",
       "  mean: 0.96728, std: 0.01281, params: {'max_depth': 4, 'min_child_weight': 1},\n",
       "  mean: 0.97123, std: 0.00755, params: {'max_depth': 4, 'min_child_weight': 2},\n",
       "  mean: 0.96791, std: 0.01005, params: {'max_depth': 4, 'min_child_weight': 3}],\n",
       " {'max_depth': 4, 'min_child_weight': 2},\n",
       " 0.9712332694397402)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[2,3,4],\n",
    " 'min_child_weight':[1,2,3]\n",
    "}\n",
    "xgbc2 = XGBClassifier(\n",
    "    learning_rate=0.5,\n",
    "    n_estimators=150,\n",
    "    max_depth=7,\n",
    "    min_child_weight=3,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='multi:softprob',\n",
    "    nthread=4, \n",
    "    scale_pos_weight=1,\n",
    "    seed=27)\n",
    "\n",
    "gsearch2 = GridSearchCV(\n",
    "    estimator = xgbc2, \n",
    "    param_grid = param_test2,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=4,\n",
    "    iid=False,\n",
    "    cv=5,\n",
    "    verbose=8)\n",
    "with parallel_backend('threading'):\n",
    "    gsearch2.fit(train_X, train_y)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] gamma=0.0 .......................................................\n",
      "[CV] gamma=0.0 .......................................................\n",
      "[CV] gamma=0.0 .......................................................\n",
      "[CV] gamma=0.0 .......................................................\n",
      "[CV] .................. gamma=0.0, score=0.973244147157, total=   0.6s\n",
      "[CV] gamma=0.0 .......................................................\n",
      "[CV] .................. gamma=0.0, score=0.970297029703, total=   0.7s\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] .................. gamma=0.0, score=0.946308724832, total=   0.8s\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] .................. gamma=0.0, score=0.973333333333, total=   0.9s\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] .................. gamma=0.0, score=0.976271186441, total=   0.8s\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] .................. gamma=0.1, score=0.963696369637, total=   0.8s\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] .................. gamma=0.1, score=0.966666666667, total=   0.7s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] .................. gamma=0.1, score=0.969899665552, total=   0.7s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] .................. gamma=0.1, score=0.953020134228, total=   0.7s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] .................. gamma=0.2, score=0.970297029703, total=   0.7s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] .................. gamma=0.1, score=0.979661016949, total=   0.8s\n",
      "[CV] gamma=0.2 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. gamma=0.2, score=0.973333333333, total=   0.8s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] .................. gamma=0.2, score=0.966555183946, total=   0.6s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] .................. gamma=0.2, score=0.979661016949, total=   0.7s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] .................. gamma=0.2, score=0.942953020134, total=   0.8s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] ................... gamma=0.3, score=0.96699669967, total=   0.9s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] .................. gamma=0.3, score=0.973333333333, total=   0.6s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] .................. gamma=0.3, score=0.942953020134, total=   0.7s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] .................. gamma=0.3, score=0.963210702341, total=   0.8s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] ................... gamma=0.4, score=0.96699669967, total=   0.6s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] .................. gamma=0.3, score=0.972881355932, total=   0.8s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] .................. gamma=0.4, score=0.963210702341, total=   0.7s\n",
      "[CV] ............................ gamma=0.4, score=0.97, total=   0.8s\n",
      "[CV] .................. gamma=0.4, score=0.942953020134, total=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  22 out of  25 | elapsed:    4.5s remaining:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. gamma=0.4, score=0.976271186441, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.96789, std: 0.01096, params: {'gamma': 0.0},\n",
       "  mean: 0.96659, std: 0.00865, params: {'gamma': 0.1},\n",
       "  mean: 0.96656, std: 0.01256, params: {'gamma': 0.2},\n",
       "  mean: 0.96388, std: 0.01112, params: {'gamma': 0.3},\n",
       "  mean: 0.96389, std: 0.01131, params: {'gamma': 0.4}],\n",
       " {'gamma': 0.0},\n",
       " 0.9678908842932774)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "xgbc3 = XGBClassifier(\n",
    "    learning_rate =0.5,\n",
    "    n_estimators=150,\n",
    "    max_depth=2,\n",
    "    min_child_weight=3,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='multi:softprob',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27)\n",
    "gsearch3 = GridSearchCV(\n",
    "    estimator = xgbc3, \n",
    "    param_grid = param_test3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=4,\n",
    "    iid=False,\n",
    "    cv=5,\n",
    "    verbose=8)\n",
    "with parallel_backend('threading'):\n",
    "    gsearch3.fit(train_X, train_y)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] subsample=0.6, colsample_bytree=0.6 .............................\n",
      "[CV] subsample=0.6, colsample_bytree=0.6 .............................\n",
      "[CV] subsample=0.6, colsample_bytree=0.6 .............................\n",
      "[CV] subsample=0.6, colsample_bytree=0.6 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.6, score=0.966666666667, total=   0.6s\n",
      "[CV] subsample=0.6, colsample_bytree=0.6 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.6, score=0.936241610738, total=   0.6s\n",
      "[CV] subsample=0.7, colsample_bytree=0.6 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.6, score=0.963696369637, total=   0.6s\n",
      "[CV] subsample=0.7, colsample_bytree=0.6 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.6, score=0.979933110368, total=   0.8s\n",
      "[CV] subsample=0.7, colsample_bytree=0.6 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.6, score=0.970297029703, total=   0.6s\n",
      "[CV] subsample=0.7, colsample_bytree=0.6 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.6, score=0.972881355932, total=   0.7s\n",
      "[CV] subsample=0.7, colsample_bytree=0.6 .............................\n",
      "[CV] .. subsample=0.7, colsample_bytree=0.6, score=0.98, total=   0.7s\n",
      "[CV] subsample=0.8, colsample_bytree=0.6 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.6, score=0.966555183946, total=   0.7s\n",
      "[CV] subsample=0.8, colsample_bytree=0.6 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.6, score=0.96699669967, total=   0.6s\n",
      "[CV] subsample=0.8, colsample_bytree=0.6 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.6, score=0.972881355932, total=   0.6s\n",
      "[CV] subsample=0.8, colsample_bytree=0.6 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.6, score=0.942953020134, total=   0.8s\n",
      "[CV] subsample=0.8, colsample_bytree=0.6 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.8, colsample_bytree=0.6, score=0.963333333333, total=   0.6s\n",
      "[CV] subsample=0.9, colsample_bytree=0.6 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.6, score=0.966555183946, total=   0.6s\n",
      "[CV] subsample=0.9, colsample_bytree=0.6 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.6, score=0.956375838926, total=   0.7s\n",
      "[CV] subsample=0.9, colsample_bytree=0.6 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.6, score=0.969491525424, total=   0.7s\n",
      "[CV] subsample=0.9, colsample_bytree=0.6 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.6, score=0.957095709571, total=   0.7s\n",
      "[CV] subsample=0.9, colsample_bytree=0.6 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.6, score=0.966666666667, total=   0.6s\n",
      "[CV] subsample=0.6, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.6, score=0.979933110368, total=   0.7s\n",
      "[CV] subsample=0.6, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.6, score=0.966101694915, total=   0.6s\n",
      "[CV] subsample=0.6, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.6, score=0.946308724832, total=   0.7s\n",
      "[CV] subsample=0.6, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.7, score=0.976897689769, total=   0.7s\n",
      "[CV] subsample=0.6, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.7, score=0.963333333333, total=   0.6s\n",
      "[CV] subsample=0.7, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.7, score=0.983277591973, total=   0.6s\n",
      "[CV] subsample=0.7, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.7, score=0.942953020134, total=   0.7s\n",
      "[CV] subsample=0.7, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.7, score=0.976271186441, total=   0.6s\n",
      "[CV] subsample=0.7, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.7, score=0.96699669967, total=   0.7s\n",
      "[CV] subsample=0.7, colsample_bytree=0.7 .............................\n",
      "[CV] .. subsample=0.7, colsample_bytree=0.7, score=0.96, total=   0.6s\n",
      "[CV] subsample=0.8, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.7, score=0.969899665552, total=   0.7s\n",
      "[CV] subsample=0.8, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.7, score=0.94966442953, total=   0.7s\n",
      "[CV] subsample=0.8, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.7, score=0.972881355932, total=   0.7s\n",
      "[CV] subsample=0.8, colsample_bytree=0.7 .............................\n",
      "[CV] .. subsample=0.8, colsample_bytree=0.7, score=0.96, total=   0.6s\n",
      "[CV] subsample=0.8, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.7, score=0.973597359736, total=   0.7s\n",
      "[CV] subsample=0.9, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.7, score=0.973244147157, total=   0.8s\n",
      "[CV] subsample=0.9, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.7, score=0.94966442953, total=   0.7s\n",
      "[CV] subsample=0.9, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.7, score=0.960396039604, total=   0.6s\n",
      "[CV] subsample=0.9, colsample_bytree=0.7 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.7, score=0.979661016949, total=   0.6s\n",
      "[CV] subsample=0.9, colsample_bytree=0.7 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    6.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. subsample=0.9, colsample_bytree=0.7, score=0.96, total=   0.8s\n",
      "[CV] subsample=0.6, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.7, score=0.966101694915, total=   0.7s\n",
      "[CV] subsample=0.6, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.7, score=0.942953020134, total=   0.7s\n",
      "[CV] subsample=0.6, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.7, score=0.973244147157, total=   0.8s\n",
      "[CV] subsample=0.6, colsample_bytree=0.8 .............................\n",
      "[CV] .. subsample=0.6, colsample_bytree=0.8, score=0.95, total=   0.6s\n",
      "[CV] subsample=0.6, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.8, score=0.963696369637, total=   0.7s\n",
      "[CV] subsample=0.7, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.8, score=0.942953020134, total=   0.7s\n",
      "[CV] subsample=0.7, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.8, score=0.966555183946, total=   0.9s\n",
      "[CV] subsample=0.7, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.8, score=0.96699669967, total=   0.7s\n",
      "[CV] subsample=0.7, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.8, score=0.979661016949, total=   0.8s\n",
      "[CV] subsample=0.7, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.8, score=0.966666666667, total=   0.7s\n",
      "[CV] subsample=0.8, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.8, score=0.973244147157, total=   0.7s\n",
      "[CV] subsample=0.8, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.8, score=0.93288590604, total=   0.7s\n",
      "[CV] subsample=0.8, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.8, score=0.972881355932, total=   0.7s\n",
      "[CV] subsample=0.8, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.8, score=0.963696369637, total=   0.7s\n",
      "[CV] subsample=0.8, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.8, score=0.966666666667, total=   0.7s\n",
      "[CV] subsample=0.9, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.8, score=0.969899665552, total=   0.7s\n",
      "[CV] subsample=0.9, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.8, score=0.953020134228, total=   0.6s\n",
      "[CV] subsample=0.9, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.8, score=0.979661016949, total=   0.8s\n",
      "[CV] subsample=0.9, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.8, score=0.970297029703, total=   0.7s\n",
      "[CV] subsample=0.9, colsample_bytree=0.8 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.8, score=0.969899665552, total=   0.7s\n",
      "[CV] subsample=0.6, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.8, score=0.963333333333, total=   0.7s\n",
      "[CV] subsample=0.6, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.8, score=0.939597315436, total=   0.6s\n",
      "[CV] subsample=0.6, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.8, score=0.983050847458, total=   0.6s\n",
      "[CV] subsample=0.6, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.9, score=0.970297029703, total=   0.7s\n",
      "[CV] subsample=0.6, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.9, score=0.929530201342, total=   0.7s\n",
      "[CV] subsample=0.7, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.6, colsample_bytree=0.9, score=0.959866220736, total=   0.8s\n",
      "[CV] subsample=0.7, colsample_bytree=0.9 .............................\n",
      "[CV] .. subsample=0.6, colsample_bytree=0.9, score=0.96, total=   0.9s\n",
      "[CV] subsample=0.7, colsample_bytree=0.9 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   11.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.6, colsample_bytree=0.9, score=0.976271186441, total=   0.9s\n",
      "[CV] subsample=0.7, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.9, score=0.970297029703, total=   0.7s\n",
      "[CV] subsample=0.7, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.9, score=0.966666666667, total=   0.8s\n",
      "[CV] subsample=0.8, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.9, score=0.95652173913, total=   0.9s\n",
      "[CV] subsample=0.8, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.9, score=0.942953020134, total=   0.7s\n",
      "[CV] subsample=0.8, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.7, colsample_bytree=0.9, score=0.979661016949, total=   0.8s\n",
      "[CV] subsample=0.8, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.9, score=0.970297029703, total=   0.8s\n",
      "[CV] subsample=0.8, colsample_bytree=0.9 .............................\n",
      "[CV] .. subsample=0.8, colsample_bytree=0.9, score=0.96, total=   0.9s\n",
      "[CV] subsample=0.9, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.9, score=0.969899665552, total=   0.8s\n",
      "[CV] subsample=0.9, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.9, score=0.956375838926, total=   0.8s\n",
      "[CV] subsample=0.9, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.8, colsample_bytree=0.9, score=0.969491525424, total=   0.7s\n",
      "[CV] subsample=0.9, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.9, score=0.957095709571, total=   0.7s\n",
      "[CV] subsample=0.9, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.9, score=0.966666666667, total=   0.7s\n",
      "[CV]  subsample=0.9, colsample_bytree=0.9, score=0.939597315436, total=   0.7s\n",
      "[CV]  subsample=0.9, colsample_bytree=0.9, score=0.979933110368, total=   0.8s\n",
      "[CV]  subsample=0.9, colsample_bytree=0.9, score=0.979661016949, total=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:   14.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.96388, std: 0.01490, params: {'subsample': 0.6, 'colsample_bytree': 0.6},\n",
       "  mean: 0.96654, std: 0.01258, params: {'subsample': 0.7, 'colsample_bytree': 0.6},\n",
       "  mean: 0.96455, std: 0.00453, params: {'subsample': 0.8, 'colsample_bytree': 0.6},\n",
       "  mean: 0.96322, std: 0.01116, params: {'subsample': 0.9, 'colsample_bytree': 0.6},\n",
       "  mean: 0.96855, std: 0.01434, params: {'subsample': 0.6, 'colsample_bytree': 0.7},\n",
       "  mean: 0.96389, std: 0.00830, params: {'subsample': 0.7, 'colsample_bytree': 0.7},\n",
       "  mean: 0.96723, std: 0.01088, params: {'subsample': 0.8, 'colsample_bytree': 0.7},\n",
       "  mean: 0.96054, std: 0.01002, params: {'subsample': 0.9, 'colsample_bytree': 0.7},\n",
       "  mean: 0.96057, std: 0.01290, params: {'subsample': 0.6, 'colsample_bytree': 0.8},\n",
       "  mean: 0.96253, std: 0.01508, params: {'subsample': 0.7, 'colsample_bytree': 0.8},\n",
       "  mean: 0.96659, std: 0.00865, params: {'subsample': 0.8, 'colsample_bytree': 0.8},\n",
       "  mean: 0.96524, std: 0.01432, params: {'subsample': 0.9, 'colsample_bytree': 0.8},\n",
       "  mean: 0.95919, std: 0.01610, params: {'subsample': 0.6, 'colsample_bytree': 0.9},\n",
       "  mean: 0.96322, std: 0.01255, params: {'subsample': 0.7, 'colsample_bytree': 0.9},\n",
       "  mean: 0.96521, std: 0.00585, params: {'subsample': 0.8, 'colsample_bytree': 0.9},\n",
       "  mean: 0.96459, std: 0.01515, params: {'subsample': 0.9, 'colsample_bytree': 0.9}],\n",
       " {'colsample_bytree': 0.7, 'subsample': 0.6},\n",
       " 0.9685465643300921)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "xgbc4 = XGBClassifier(\n",
    "    learning_rate =0.5,\n",
    "    n_estimators=150,\n",
    "    max_depth=2,\n",
    "    min_child_weight=3,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='multi:softprob',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27)\n",
    "gsearch4 = GridSearchCV(\n",
    "    estimator = xgbc4, \n",
    "    param_grid = param_test4,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=4,\n",
    "    iid=False,\n",
    "    cv=5,\n",
    "    verbose=8)\n",
    "with parallel_backend('threading'):\n",
    "    gsearch4.fit(train_X, train_y)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] subsample=0.85, colsample_bytree=0.85 ...........................\n",
      "[CV] subsample=0.85, colsample_bytree=0.85 ...........................\n",
      "[CV] subsample=0.85, colsample_bytree=0.85 ...........................\n",
      "[CV] subsample=0.85, colsample_bytree=0.85 ...........................\n",
      "[CV]  subsample=0.85, colsample_bytree=0.85, score=0.95652173913, total=   0.6s\n",
      "[CV] subsample=0.85, colsample_bytree=0.85 ...........................\n",
      "[CV]  subsample=0.85, colsample_bytree=0.85, score=0.963333333333, total=   0.7s\n",
      "[CV] subsample=0.9, colsample_bytree=0.85 ............................\n",
      "[CV]  subsample=0.85, colsample_bytree=0.85, score=0.973597359736, total=   0.8s\n",
      "[CV] subsample=0.9, colsample_bytree=0.85 ............................\n",
      "[CV]  subsample=0.85, colsample_bytree=0.85, score=0.942953020134, total=   0.9s\n",
      "[CV] subsample=0.9, colsample_bytree=0.85 ............................\n",
      "[CV]  subsample=0.85, colsample_bytree=0.85, score=0.979661016949, total=   0.6s\n",
      "[CV] subsample=0.9, colsample_bytree=0.85 ............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.85, score=0.966666666667, total=   0.5s\n",
      "[CV] subsample=0.9, colsample_bytree=0.85 ............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.85, score=0.96699669967, total=   0.7s\n",
      "[CV] subsample=0.95, colsample_bytree=0.85 ...........................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.85, score=0.963210702341, total=   0.8s\n",
      "[CV] subsample=0.95, colsample_bytree=0.85 ...........................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.85, score=0.939597315436, total=   0.6s\n",
      "[CV] subsample=0.95, colsample_bytree=0.85 ...........................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.85, score=0.979661016949, total=   0.6s\n",
      "[CV] subsample=0.95, colsample_bytree=0.85 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.95, colsample_bytree=0.85, score=0.970297029703, total=   0.8s\n",
      "[CV] subsample=0.95, colsample_bytree=0.85 ...........................\n",
      "[CV]  subsample=0.95, colsample_bytree=0.85, score=0.963210702341, total=   0.6s\n",
      "[CV] subsample=0.85, colsample_bytree=0.9 ............................\n",
      "[CV]  subsample=0.95, colsample_bytree=0.85, score=0.973333333333, total=   0.9s\n",
      "[CV] subsample=0.85, colsample_bytree=0.9 ............................\n",
      "[CV]  subsample=0.95, colsample_bytree=0.85, score=0.942953020134, total=   0.6s\n",
      "[CV] subsample=0.85, colsample_bytree=0.9 ............................\n",
      "[CV]  subsample=0.95, colsample_bytree=0.85, score=0.976271186441, total=   0.8s\n",
      "[CV] subsample=0.85, colsample_bytree=0.9 ............................\n",
      "[CV]  subsample=0.85, colsample_bytree=0.9, score=0.973597359736, total=   0.6s\n",
      "[CV] subsample=0.85, colsample_bytree=0.9 ............................\n",
      "[CV]  subsample=0.85, colsample_bytree=0.9, score=0.95652173913, total=   0.8s\n",
      "[CV] subsample=0.9, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.85, colsample_bytree=0.9, score=0.973333333333, total=   0.9s\n",
      "[CV] subsample=0.9, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.85, colsample_bytree=0.9, score=0.983050847458, total=   0.6s\n",
      "[CV] subsample=0.9, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.85, colsample_bytree=0.9, score=0.94966442953, total=   0.7s\n",
      "[CV] subsample=0.9, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.9, score=0.957095709571, total=   0.7s\n",
      "[CV] subsample=0.9, colsample_bytree=0.9 .............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.9, score=0.966666666667, total=   0.8s\n",
      "[CV] subsample=0.95, colsample_bytree=0.9 ............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.9, score=0.979933110368, total=   0.6s\n",
      "[CV] subsample=0.95, colsample_bytree=0.9 ............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.9, score=0.939597315436, total=   0.8s\n",
      "[CV] subsample=0.95, colsample_bytree=0.9 ............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.9, score=0.979661016949, total=   0.6s\n",
      "[CV] subsample=0.95, colsample_bytree=0.9 ............................\n",
      "[CV]  subsample=0.95, colsample_bytree=0.9, score=0.963696369637, total=   0.8s\n",
      "[CV] subsample=0.95, colsample_bytree=0.9 ............................\n",
      "[CV]  subsample=0.95, colsample_bytree=0.9, score=0.966666666667, total=   0.7s\n",
      "[CV] subsample=0.85, colsample_bytree=0.95 ...........................\n",
      "[CV]  subsample=0.95, colsample_bytree=0.9, score=0.946308724832, total=   0.6s\n",
      "[CV] subsample=0.85, colsample_bytree=0.95 ...........................\n",
      "[CV]  subsample=0.95, colsample_bytree=0.9, score=0.966555183946, total=   0.7s\n",
      "[CV] subsample=0.85, colsample_bytree=0.95 ...........................\n",
      "[CV]  subsample=0.85, colsample_bytree=0.95, score=0.973597359736, total=   0.7s\n",
      "[CV] subsample=0.85, colsample_bytree=0.95 ...........................\n",
      "[CV]  subsample=0.95, colsample_bytree=0.9, score=0.972881355932, total=   0.9s\n",
      "[CV] subsample=0.85, colsample_bytree=0.95 ...........................\n",
      "[CV]  subsample=0.85, colsample_bytree=0.95, score=0.97, total=   0.6s\n",
      "[CV] subsample=0.9, colsample_bytree=0.95 ............................\n",
      "[CV]  subsample=0.85, colsample_bytree=0.95, score=0.963210702341, total=   0.9s\n",
      "[CV] subsample=0.9, colsample_bytree=0.95 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    6.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.85, colsample_bytree=0.95, score=0.986440677966, total=   0.8s\n",
      "[CV] subsample=0.9, colsample_bytree=0.95 ............................\n",
      "[CV]  subsample=0.85, colsample_bytree=0.95, score=0.953020134228, total=   0.9s\n",
      "[CV] subsample=0.9, colsample_bytree=0.95 ............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.95, score=0.960396039604, total=   0.8s\n",
      "[CV] subsample=0.9, colsample_bytree=0.95 ............................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.95, score=0.963333333333, total=   0.8s\n",
      "[CV] subsample=0.95, colsample_bytree=0.95 ...........................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.95, score=0.963210702341, total=   0.8s\n",
      "[CV] subsample=0.95, colsample_bytree=0.95 ...........................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.95, score=0.983050847458, total=   0.7s\n",
      "[CV] subsample=0.95, colsample_bytree=0.95 ...........................\n",
      "[CV]  subsample=0.9, colsample_bytree=0.95, score=0.936241610738, total=   0.8s\n",
      "[CV] subsample=0.95, colsample_bytree=0.95 ...........................\n",
      "[CV]  subsample=0.95, colsample_bytree=0.95, score=0.970297029703, total=   0.8s\n",
      "[CV] subsample=0.95, colsample_bytree=0.95 ...........................\n",
      "[CV]  subsample=0.95, colsample_bytree=0.95, score=0.969899665552, total=   0.6s\n",
      "[CV]  subsample=0.95, colsample_bytree=0.95, score=0.936241610738, total=   0.7s\n",
      "[CV]  subsample=0.95, colsample_bytree=0.95, score=0.97, total=   0.8s\n",
      "[CV]  subsample=0.95, colsample_bytree=0.95, score=0.976271186441, total=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  45 out of  45 | elapsed:    8.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.96321, std: 0.01291, params: {'subsample': 0.85, 'colsample_bytree': 0.85},\n",
       "  mean: 0.96323, std: 0.01307, params: {'subsample': 0.9, 'colsample_bytree': 0.85},\n",
       "  mean: 0.96521, std: 0.01195, params: {'subsample': 0.95, 'colsample_bytree': 0.85},\n",
       "  mean: 0.96723, std: 0.01226, params: {'subsample': 0.85, 'colsample_bytree': 0.9},\n",
       "  mean: 0.96459, std: 0.01515, params: {'subsample': 0.9, 'colsample_bytree': 0.9},\n",
       "  mean: 0.96322, std: 0.00897, params: {'subsample': 0.95, 'colsample_bytree': 0.9},\n",
       "  mean: 0.96925, std: 0.01109, params: {'subsample': 0.85, 'colsample_bytree': 0.95},\n",
       "  mean: 0.96125, std: 0.01490, params: {'subsample': 0.9, 'colsample_bytree': 0.95},\n",
       "  mean: 0.96454, std: 0.01435, params: {'subsample': 0.95, 'colsample_bytree': 0.95}],\n",
       " {'colsample_bytree': 0.95, 'subsample': 0.85},\n",
       " 0.9692537748542801)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in range(85,100,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(85,100,5)]\n",
    "}\n",
    "xgbc5 = XGBClassifier(\n",
    "    learning_rate =0.5,\n",
    "    n_estimators=150,\n",
    "    max_depth=2,\n",
    "    min_child_weight=3,\n",
    "    gamma=0.1,\n",
    "    subsample=0.6,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='multi:softprob',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27)\n",
    "gsearch5 = GridSearchCV(\n",
    "    estimator = xgbc5, \n",
    "    param_grid = param_test5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=4,\n",
    "    iid=False,\n",
    "    cv=5,\n",
    "    verbose=8)\n",
    "with parallel_backend('threading'):\n",
    "    gsearch5.fit(train_X, train_y)\n",
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] reg_alpha=1e-05 .................................................\n",
      "[CV] reg_alpha=1e-05 .................................................\n",
      "[CV] reg_alpha=1e-05 .................................................\n",
      "[CV] reg_alpha=1e-05 .................................................\n",
      "[CV] ............ reg_alpha=1e-05, score=0.973597359736, total=   0.7s\n",
      "[CV] reg_alpha=1e-05 .................................................\n",
      "[CV] ............ reg_alpha=1e-05, score=0.963333333333, total=   0.8s\n",
      "[CV] reg_alpha=0.01 ..................................................\n",
      "[CV] ............ reg_alpha=1e-05, score=0.942953020134, total=   0.8s\n",
      "[CV] reg_alpha=0.01 ..................................................\n",
      "[CV] ............. reg_alpha=1e-05, score=0.95652173913, total=   0.8s\n",
      "[CV] reg_alpha=0.01 ..................................................\n",
      "[CV] ....................... reg_alpha=0.01, score=0.97, total=   0.6s\n",
      "[CV] reg_alpha=0.01 ..................................................\n",
      "[CV] ............ reg_alpha=1e-05, score=0.979661016949, total=   0.7s\n",
      "[CV] reg_alpha=0.01 ..................................................\n",
      "[CV] ............. reg_alpha=0.01, score=0.976897689769, total=   0.8s\n",
      "[CV] reg_alpha=0.1 ...................................................\n",
      "[CV] ............. reg_alpha=0.01, score=0.959866220736, total=   0.7s\n",
      "[CV] reg_alpha=0.1 ...................................................\n",
      "[CV] ............. reg_alpha=0.01, score=0.939597315436, total=   0.7s\n",
      "[CV] reg_alpha=0.1 ...................................................\n",
      "[CV] .............. reg_alpha=0.1, score=0.973597359736, total=   0.6s\n",
      "[CV] reg_alpha=0.1 ...................................................\n",
      "[CV] ............. reg_alpha=0.01, score=0.972881355932, total=   0.8s\n",
      "[CV] reg_alpha=0.1 ...................................................\n",
      "[CV] .............. reg_alpha=0.1, score=0.963333333333, total=   0.7s\n",
      "[CV] reg_alpha=1 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. reg_alpha=0.1, score=0.939597315436, total=   0.6s\n",
      "[CV] reg_alpha=1 .....................................................\n",
      "[CV] .............. reg_alpha=0.1, score=0.979661016949, total=   0.7s\n",
      "[CV] reg_alpha=1 .....................................................\n",
      "[CV] .............. reg_alpha=0.1, score=0.953177257525, total=   0.8s\n",
      "[CV] reg_alpha=1 .....................................................\n",
      "[CV] ................ reg_alpha=1, score=0.980198019802, total=   0.9s\n",
      "[CV] reg_alpha=1 .....................................................\n",
      "[CV] .......................... reg_alpha=1, score=0.97, total=   0.9s\n",
      "[CV] reg_alpha=100 ...................................................\n",
      "[CV] ................. reg_alpha=1, score=0.93288590604, total=   0.8s\n",
      "[CV] reg_alpha=100 ...................................................\n",
      "[CV] ................. reg_alpha=1, score=0.94983277592, total=   1.0s\n",
      "[CV] reg_alpha=100 ...................................................\n",
      "[CV] ................ reg_alpha=1, score=0.979661016949, total=   0.9s\n",
      "[CV] reg_alpha=100 ...................................................\n",
      "[CV] .............. reg_alpha=100, score=0.683168316832, total=   0.9s\n",
      "[CV] reg_alpha=100 ...................................................\n",
      "[CV] ........................ reg_alpha=100, score=0.69, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  22 out of  25 | elapsed:    4.7s remaining:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. reg_alpha=100, score=0.695652173913, total=   1.0s\n",
      "[CV] .............. reg_alpha=100, score=0.694630872483, total=   0.9s\n",
      "[CV] ............... reg_alpha=100, score=0.71186440678, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:    5.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.96321, std: 0.01291, params: {'reg_alpha': 1e-05},\n",
       "  mean: 0.96385, std: 0.01337, params: {'reg_alpha': 0.01},\n",
       "  mean: 0.96187, std: 0.01434, params: {'reg_alpha': 0.1},\n",
       "  mean: 0.96252, std: 0.01845, params: {'reg_alpha': 1},\n",
       "  mean: 0.69506, std: 0.00949, params: {'reg_alpha': 100}],\n",
       " {'reg_alpha': 0.01},\n",
       " 0.9638485163746416)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "xgbc6 = XGBClassifier(\n",
    "    learning_rate =0.5,\n",
    "    n_estimators=150,\n",
    "    max_depth=2,\n",
    "    min_child_weight=3,\n",
    "    gamma=0.1,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    objective='multi:softprob',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27)\n",
    "gsearch6 = GridSearchCV(\n",
    "    estimator = xgbc6, \n",
    "    param_grid = param_test6,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=4,\n",
    "    iid=False,\n",
    "    cv=5,\n",
    "    verbose=8)\n",
    "with parallel_backend('threading'):\n",
    "    gsearch6.fit(train_X, train_y)\n",
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(alg,train_X,train_y,pred_X,pred_y=None):\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(train_X, train_y, eval_metric='merror')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dpred_predictions = alg.predict(pred_X)\n",
    "    dpred_predprob = alg.predict_proba(pred_X)\n",
    "        \n",
    "    #Print model report:\n",
    "    print('\\nModel Report')\n",
    "    print(pred_y)\n",
    "    print('Logloss : %s' % (metrics.log_loss(pred_y, dpred_predprob, eps=1e-15)))\n",
    "    print('Accuracy : %.4g' % metrics.accuracy_score(pred_y, dpred_predictions))\n",
    "    print('classification_report :\\n%s' % metrics.classification_report(pred_y, dpred_predictions))\n",
    "#     print(dir(alg))\n",
    "    _booster = alg.get_booster()\n",
    "    _score = _booster.get_fscore()\n",
    "    feat_imp = pd.Series(_score).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    return dpred_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "[ 5  5  5  5  9  5  5  2  0  8  5  1 10  5  7  5  4  5  4  5  5  5  1  0\n",
      "  5  5  5  5  5  5  5  7  5  5  5  5  6  5  7  5  5  5  5  7  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  7  5  4  5  5  5  9  5  5  5  5  5  5  5\n",
      "  5  5  5  1  0  5  5  6  5  5  5  5  5  5  5  5  5  7  5  5  5  5  5  4\n",
      "  8  4  8  5  5  5  9  5  5  5 10  1  9  7  5  1  5  5  9  5  5  5  5  5\n",
      "  3  0 10  5  9  5  9  4  5  5  5  5  5  7  5  5  5  5  5  5  5  5  5  5\n",
      " 10  7  8  5  7  4  4  9  5  5  4  5  5  5  5  7  6  5  9  5  4  5  5  5\n",
      "  5  5  1  5 10  5  0  5  8  5  4  5  5  5  5  0  5  5  5  5  6  1 10  5\n",
      "  5  5  7  0  7  5  5  5  7  5  2  2  3  5  5  5  5  5  5  6  5  5  5  5\n",
      "  5  5  9 10  4  5  5  5  6  5  5  0  5  5  5  5  5  5  5  5  7  5  5  5\n",
      "  1  5  5  5  8  5  9  7  5  5  1  4  4  7  7  5  4  5  5  1  5  5  7  5\n",
      "  5  1  5  5  5  5  1  4  9  1  5  5  5  5  5  3  5  5  5  5  5  5  5  5\n",
      "  7  5  5  7  5  1  5  5  5  5  7  5  7  4  5  5  3  5  5  5  7  2  5  5\n",
      "  7  7  5  5  5  7  5  5  5  5  5  5  5  5  5  5  9  7  5  7  4  5  6  5\n",
      "  5  7  5  5  5  5  5  5  5  8  9  5  5  5  9 10  5  5  1  5  5  9  5  1\n",
      "  5  5  5  5  4  5  7  5  5  5  5  5  5  5  2  5  5  5  5  7  5  5  5  5\n",
      "  5  7  5 10  5  1  5  5  0  5  5  5  5  5  5  5  5  5  5  5  8  5  7  7\n",
      "  1  5  4  5  5  5  5  5  5  2  2  5  7  5  5  5  5  5  5  5 10  5  5  7\n",
      "  5  4  5  5  4  5  5  5  5  5  7  5  4  5  5  5  1 10  5  5 10  5  5  1\n",
      "  5  5  5  5  7  5  5  5  5  7  1  5  5  5  7  5  7  5  7  5  5  5  1  5\n",
      "  5  5  1  5  5  5  1  0  5  5  1  5 10  8  5  5  8  5  5  7  7  5  5  5]\n",
      "Logloss : 0.07701177837832672\n",
      "Accuracy : 0.9722\n",
      "classification_report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90        10\n",
      "          1       1.00      0.88      0.94        25\n",
      "          2       1.00      0.57      0.73         7\n",
      "          3       1.00      0.75      0.86         4\n",
      "          4       0.96      1.00      0.98        23\n",
      "          5       0.99      1.00      0.99       344\n",
      "          6       0.80      0.57      0.67         7\n",
      "          7       0.94      0.98      0.96        45\n",
      "          8       1.00      1.00      1.00        10\n",
      "          9       0.89      1.00      0.94        16\n",
      "         10       0.92      0.92      0.92        13\n",
      "\n",
      "avg / total       0.97      0.97      0.97       504\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAEPCAYAAACJC+iCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_final = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=5000,\n",
    " max_depth=2,\n",
    " min_child_weight=3,\n",
    " gamma=0.1,\n",
    " subsample=0.85,\n",
    " colsample_bytree=0.85,\n",
    " objective='multi:softprob',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " reg_alpha=0.01,\n",
    " seed=27)\n",
    "\n",
    "pred = model_predict(xgb_final,train_X,train_y,test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "怎么没有显示物流到哪里了\n",
      "无物流信息\n",
      "物流无更新\n",
      "能帮我查一下这单是没去收还是收了没发吗？\n",
      "快递查询\n",
      "货品丢失\n",
      "这个快递昨天就到湘潭市了今天还没送\n",
      "网点无配送\n",
      "催单\n",
      "麻烦您帮我查一下\n",
      "快递查询\n",
      "无意图\n",
      "能不帮我查一下我的订单今天何时配送\n",
      "到货时间查询\n",
      "催单\n",
      "效率慢\n",
      "催单\n",
      "无意图\n",
      "单号寄的人没拍给我，只拍了这个\n",
      "无订单号\n",
      "无意图\n",
      "这个快递是不是今天派送\n",
      "到货时间查询\n",
      "网点无配送\n",
      "#这个电话号码是快递站点的电话，我打给他他不接电话\n",
      "无意图\n",
      "询问电话\n",
      "能查到快递吗？\n",
      "快递查询\n",
      "无意图\n",
      "快点查不到\n",
      "无物流信息\n",
      "快递查询\n",
      "揽件6天了还没有动静\n",
      "无物流信息\n",
      "物流无更新\n",
      "好，把台州这个中通号码发我\n",
      "询问电话\n",
      "无意图\n",
      "快递已到泉州市，希望今天能派送到家\n",
      "到货时间查询\n",
      "催单\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "for i in range(len(test_data)):\n",
    "    if test_data[i]['label'] != label_dict[pred[i]]:\n",
    "        print(test_data[i]['text'])\n",
    "        print(test_data[i]['label'])\n",
    "        print(label_dict[pred[i]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, 504)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pred),len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(pred)):\n",
    "    preds.append(label_dict[pred[i]].encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/pred.csv')\n",
    "df['second_pred'] = preds\n",
    "wuyitu = df[df['pred'] == 0].index.tolist()\n",
    "youyitu = df[df['pred'] != 0].index.tolist()\n",
    "df.loc[wuyitu, 'final_pred'] = '无意图'\n",
    "df.loc[youyitu, 'final_pred'] = df.loc[youyitu, 'second_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>text</th>\n",
       "      <th>second_pred</th>\n",
       "      <th>final_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>询问电话</td>\n",
       "      <td>0</td>\n",
       "      <td>合肥蜀山四部的电话，我有快递显示无法联系</td>\n",
       "      <td>询问电话</td>\n",
       "      <td>无意图</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>无意图</td>\n",
       "      <td>0</td>\n",
       "      <td>#这个电话号码是快递站点的电话，我打给他他不接电话</td>\n",
       "      <td>询问电话</td>\n",
       "      <td>无意图</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  pred                       text second_pred final_pred\n",
       "12   询问电话     0       合肥蜀山四部的电话，我有快递显示无法联系        询问电话        无意图\n",
       "284   无意图     0  #这个电话号码是快递站点的电话，我打给他他不接电话        询问电话        无意图"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['final_pred'] != df['second_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>text</th>\n",
       "      <th>second_pred</th>\n",
       "      <th>final_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>无物流信息</td>\n",
       "      <td>1</td>\n",
       "      <td>怎么没有显示物流到哪里了</td>\n",
       "      <td>物流无更新</td>\n",
       "      <td>物流无更新</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>询问电话</td>\n",
       "      <td>0</td>\n",
       "      <td>合肥蜀山四部的电话，我有快递显示无法联系</td>\n",
       "      <td>询问电话</td>\n",
       "      <td>无意图</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>快递查询</td>\n",
       "      <td>1</td>\n",
       "      <td>能帮我查一下这单是没去收还是收了没发吗？</td>\n",
       "      <td>货品丢失</td>\n",
       "      <td>货品丢失</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>网点无配送</td>\n",
       "      <td>1</td>\n",
       "      <td>这个快递昨天就到湘潭市了今天还没送</td>\n",
       "      <td>催单</td>\n",
       "      <td>催单</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>快递查询</td>\n",
       "      <td>1</td>\n",
       "      <td>麻烦您帮我查一下</td>\n",
       "      <td>无意图</td>\n",
       "      <td>无意图</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>到货时间查询</td>\n",
       "      <td>1</td>\n",
       "      <td>能不帮我查一下我的订单今天何时配送</td>\n",
       "      <td>催单</td>\n",
       "      <td>催单</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>催单</td>\n",
       "      <td>0</td>\n",
       "      <td>效率慢</td>\n",
       "      <td>无意图</td>\n",
       "      <td>无意图</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>无订单号</td>\n",
       "      <td>1</td>\n",
       "      <td>单号寄的人没拍给我，只拍了这个</td>\n",
       "      <td>无意图</td>\n",
       "      <td>无意图</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>到货时间查询</td>\n",
       "      <td>1</td>\n",
       "      <td>这个快递是不是今天派送</td>\n",
       "      <td>网点无配送</td>\n",
       "      <td>网点无配送</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>快递查询</td>\n",
       "      <td>1</td>\n",
       "      <td>能查到快递吗？</td>\n",
       "      <td>无意图</td>\n",
       "      <td>无意图</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>无物流信息</td>\n",
       "      <td>1</td>\n",
       "      <td>快点查不到</td>\n",
       "      <td>快递查询</td>\n",
       "      <td>快递查询</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>无物流信息</td>\n",
       "      <td>1</td>\n",
       "      <td>揽件6天了还没有动静</td>\n",
       "      <td>物流无更新</td>\n",
       "      <td>物流无更新</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>询问电话</td>\n",
       "      <td>1</td>\n",
       "      <td>好，把台州这个中通号码发我</td>\n",
       "      <td>无意图</td>\n",
       "      <td>无意图</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>到货时间查询</td>\n",
       "      <td>1</td>\n",
       "      <td>快递已到泉州市，希望今天能派送到家</td>\n",
       "      <td>催单</td>\n",
       "      <td>催单</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  pred                  text second_pred final_pred\n",
       "7     无物流信息     1          怎么没有显示物流到哪里了       物流无更新      物流无更新\n",
       "12     询问电话     0  合肥蜀山四部的电话，我有快递显示无法联系        询问电话        无意图\n",
       "36     快递查询     1  能帮我查一下这单是没去收还是收了没发吗？        货品丢失       货品丢失\n",
       "121   网点无配送     1     这个快递昨天就到湘潭市了今天还没送          催单         催单\n",
       "160    快递查询     1              麻烦您帮我查一下         无意图        无意图\n",
       "170  到货时间查询     1     能不帮我查一下我的订单今天何时配送          催单         催单\n",
       "196      催单     0                   效率慢         无意图        无意图\n",
       "204    无订单号     1       单号寄的人没拍给我，只拍了这个         无意图        无意图\n",
       "270  到货时间查询     1           这个快递是不是今天派送       网点无配送      网点无配送\n",
       "334    快递查询     1               能查到快递吗？         无意图        无意图\n",
       "417   无物流信息     1                 快点查不到        快递查询       快递查询\n",
       "418   无物流信息     1            揽件6天了还没有动静       物流无更新      物流无更新\n",
       "452    询问电话     1         好，把台州这个中通号码发我         无意图        无意图\n",
       "455  到货时间查询     1     快递已到泉州市，希望今天能派送到家          催单         催单"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label'] != df['final_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9722222222222222, 0.9722222222222222)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 * len(df[df['label'] == df['final_pred']]) / len(df),1.0 * len(df[df['label'] == df['second_pred']]) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345, 348, 350)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['pred'] == 0]),len(df[df['second_pred'] == '无意图']),len(df[df['final_pred'] == '无意图'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'int'>\n",
      "<type 'int'>\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "pred = []\n",
    "preds = list(df['final_pred'])\n",
    "for i in range(len(test_data)):\n",
    "    for key in label_dict:\n",
    "        if test_data[i]['label'] == label_dict[key]:\n",
    "            labels.append(key)\n",
    "            break\n",
    "    for key in label_dict:\n",
    "        if preds[i] == label_dict[key].encode('utf-8'):\n",
    "            pred.append(key)\n",
    "            break    \n",
    "print(type(labels[0]))\n",
    "print(type(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "网点无配送\n",
      "1\n",
      "到货时间查询\n",
      "2\n",
      "无物流信息\n",
      "3\n",
      "无订单号\n",
      "4\n",
      "货品丢失\n",
      "5\n",
      "无意图\n",
      "6\n",
      "快递查询\n",
      "7\n",
      "催单\n",
      "8\n",
      "查询位置\n",
      "9\n",
      "物流无更新\n",
      "10\n",
      "询问电话\n"
     ]
    }
   ],
   "source": [
    "for key in label_dict:\n",
    "    print(key)\n",
    "    print(label_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90        10\n",
      "          1       1.00      0.88      0.94        25\n",
      "          2       1.00      0.57      0.73         7\n",
      "          3       1.00      0.75      0.86         4\n",
      "          4       0.96      1.00      0.98        23\n",
      "          5       0.98      1.00      0.99       344\n",
      "          6       0.80      0.57      0.67         7\n",
      "          7       0.94      0.98      0.96        45\n",
      "          8       1.00      1.00      1.00        10\n",
      "          9       0.89      1.00      0.94        16\n",
      "         10       1.00      0.85      0.92        13\n",
      "\n",
      "avg / total       0.97      0.97      0.97       504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification_report :\\n%s' % metrics.classification_report(labels, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfenv.v1.2]",
   "language": "python",
   "name": "conda-env-tfenv.v1.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
