{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.328 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 1006 user-define jieba dict success!\n"
     ]
    }
   ],
   "source": [
    "from model_comparer import *\n",
    "from data_converter import load_data\n",
    "from data_converter import down_sample_data\n",
    "import pickle\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "# from __future__ import unicode_literals\n",
    "#logger.start('../log/quantize.log', __name__, 'DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_first_binary_classify = IntentClassify(\n",
    "    [(2, 10, 100, 0.2)], use_rule=False, \n",
    "    token_func=lambda x:FasttextClassifier.fasttext_tokenize(x['text'], char=True, filter_stop_word=True),\n",
    "    pretrain='../conf/fasttext.model.min30_ngram5_d100_it20.vec'\n",
    ")\n",
    "save_model = model_first_binary_classify\n",
    "infos = load_data('../data/taged.txt')\n",
    "#down_sample_data(infos, '../data/_train.txt', '../data/_test.txt',10,)\n",
    "down_sample_data(infos, '../data/_test.txt', '../data/_train.txt', '../data/_total.txt', 20,)\n",
    "train_data = load_train_data('../data/_train.txt')\n",
    "test_data = load_train_data('../data/_test.txt')\n",
    "recall = train_test_validation(save_model, train_data, test_data, save_fpath='../data/train_test_results/binary_classify_result.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 1999 origin infos from ../data/taged.txt \n",
      "save 214 data to ../data/_test.txt\n",
      "save 1785 data to ../data/_train.txt\n",
      "save 1999 data to ../data/_total.txt\n",
      "load 1785 test data form ../data/_train.txt\n",
      "load 214 test data form ../data/_test.txt\n",
      "pretrainedVectors: ../conf/fasttext.model.min30_ngram5_d100_it20.vec \n",
      "save model to ./tmp_bin/model_27374_2018-08-07_16-48-30.bin.\n",
      "------\n",
      "FasttextCV failed, errmsg='FasttextClassifier' object has no attribute 'quantize'\n",
      "fit 1 models success!\n",
      "save 82 badcases to ../data/train_test_results/binary_classify_result.txt \n",
      "--------------------------------------------------------------------------------\n",
      "model_num=1, recall=0.616822, Prec=0.616822, f1-score=0.616822429907\n",
      "1\t430\t194\t0.577319587629\t112\t1.0\n",
      "0\t1355\t20\t1.0\t102\t0.196078431373\n",
      "all\t1785\t214\t0.616822429907\t214\t0.616822429907\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfenv.v1.2]",
   "language": "python",
   "name": "conda-env-tfenv.v1.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
